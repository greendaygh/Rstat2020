<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 8 Statistical inference | R로 배우는 기초통계</title>
  <meta name="description" content="UST lecture web site" />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 8 Statistical inference | R로 배우는 기초통계" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="UST lecture web site" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 8 Statistical inference | R로 배우는 기초통계" />
  
  <meta name="twitter:description" content="UST lecture web site" />
  

<meta name="author" content="한국생명공학연구원 김하성" />


<meta name="date" content="2020-12-24" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="populations.html"/>
<link rel="next" href="confidence-intervals.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./"> Introduction to statistics with R </a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction 강의 개요</a>
<ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#goal-강의-목표"><i class="fa fa-check"></i><b>1.1</b> Goal 강의 목표</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#this-course"><i class="fa fa-check"></i><b>1.2</b> This course</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#tips"><i class="fa fa-check"></i><b>1.3</b> Tips</a></li>
<li class="chapter" data-level="1.4" data-path="index.html"><a href="index.html#references-books-참고-교제"><i class="fa fa-check"></i><b>1.4</b> References books 참고 교제</a></li>
<li class="chapter" data-level="1.5" data-path="index.html"><a href="index.html#references-참고-자료"><i class="fa fa-check"></i><b>1.5</b> References 참고 자료</a></li>
<li class="chapter" data-level="1.6" data-path="index.html"><a href="index.html#evaluation-평가-세부-항목"><i class="fa fa-check"></i><b>1.6</b> Evaluation 평가 세부 항목</a></li>
<li class="chapter" data-level="1.7" data-path="index.html"><a href="index.html#schedule-강의-계획"><i class="fa fa-check"></i><b>1.7</b> Schedule 강의 계획</a></li>
<li class="chapter" data-level="1.8" data-path="index.html"><a href="index.html#r-lecture-youtube-link"><i class="fa fa-check"></i><b>1.8</b> R Lecture Youtube Link</a>
<ul>
<li class="chapter" data-level="1.8.1" data-path="index.html"><a href="index.html#lecture-chapter-1"><i class="fa fa-check"></i><b>1.8.1</b> Lecture Chapter 1</a></li>
<li class="chapter" data-level="1.8.2" data-path="index.html"><a href="index.html#lecture-2"><i class="fa fa-check"></i><b>1.8.2</b> Lecture 2</a></li>
<li class="chapter" data-level="1.8.3" data-path="index.html"><a href="index.html#lecture-3"><i class="fa fa-check"></i><b>1.8.3</b> Lecture 3</a></li>
<li class="chapter" data-level="1.8.4" data-path="index.html"><a href="index.html#lecture-4"><i class="fa fa-check"></i><b>1.8.4</b> Lecture 4</a></li>
<li class="chapter" data-level="1.8.5" data-path="index.html"><a href="index.html#lecture-5"><i class="fa fa-check"></i><b>1.8.5</b> Lecture 5</a></li>
<li class="chapter" data-level="1.8.6" data-path="index.html"><a href="index.html#lecture-6"><i class="fa fa-check"></i><b>1.8.6</b> Lecture 6</a></li>
<li class="chapter" data-level="1.8.7" data-path="index.html"><a href="index.html#lecture-7"><i class="fa fa-check"></i><b>1.8.7</b> Lecture 7</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="r-basics.html"><a href="r-basics.html"><i class="fa fa-check"></i><b>2</b> R basics</a>
<ul>
<li class="chapter" data-level="2.1" data-path="r-basics.html"><a href="r-basics.html#what-is-r-rstudio"><i class="fa fa-check"></i><b>2.1</b> What is R / Rstudio</a></li>
<li class="chapter" data-level="2.2" data-path="r-basics.html"><a href="r-basics.html#r-rstudio-installation"><i class="fa fa-check"></i><b>2.2</b> R / Rstudio installation</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="r-basics.html"><a href="r-basics.html#r-설치"><i class="fa fa-check"></i><b>2.2.1</b> R 설치</a></li>
<li class="chapter" data-level="2.2.2" data-path="r-basics.html"><a href="r-basics.html#rstudio-설치"><i class="fa fa-check"></i><b>2.2.2</b> Rstudio 설치</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="r-basics.html"><a href="r-basics.html#rstudio-interface"><i class="fa fa-check"></i><b>2.3</b> Rstudio interface</a></li>
<li class="chapter" data-level="2.4" data-path="r-basics.html"><a href="r-basics.html#keyboard-shortcuts"><i class="fa fa-check"></i><b>2.4</b> Keyboard shortcuts</a></li>
<li class="chapter" data-level="2.5" data-path="r-basics.html"><a href="r-basics.html#r-programming-basics-and-terminology"><i class="fa fa-check"></i><b>2.5</b> R programming basics and terminology</a></li>
<li class="chapter" data-level="2.6" data-path="r-basics.html"><a href="r-basics.html#set-a-working-directory"><i class="fa fa-check"></i><b>2.6</b> Set a working directory</a></li>
<li class="chapter" data-level="2.7" data-path="r-basics.html"><a href="r-basics.html#r-coding-practice"><i class="fa fa-check"></i><b>2.7</b> R coding practice</a></li>
<li class="chapter" data-level="2.8" data-path="r-basics.html"><a href="r-basics.html#variables-and-values"><i class="fa fa-check"></i><b>2.8</b> Variables and values</a></li>
<li class="chapter" data-level="2.9" data-path="r-basics.html"><a href="r-basics.html#variable-type-of-storage-mode"><i class="fa fa-check"></i><b>2.9</b> Variable type of (storage) mode</a></li>
<li class="chapter" data-level="2.10" data-path="r-basics.html"><a href="r-basics.html#variable---vectors"><i class="fa fa-check"></i><b>2.10</b> Variable - Vectors</a></li>
<li class="chapter" data-level="2.11" data-path="r-basics.html"><a href="r-basics.html#functions"><i class="fa fa-check"></i><b>2.11</b> Functions</a></li>
<li class="chapter" data-level="2.12" data-path="r-basics.html"><a href="r-basics.html#vectorized-functions"><i class="fa fa-check"></i><b>2.12</b> Vectorized functions</a></li>
<li class="chapter" data-level="2.13" data-path="r-basics.html"><a href="r-basics.html#help"><i class="fa fa-check"></i><b>2.13</b> Help</a></li>
<li class="chapter" data-level="2.14" data-path="r-basics.html"><a href="r-basics.html#r-packages"><i class="fa fa-check"></i><b>2.14</b> R packages</a></li>
<li class="chapter" data-level="2.15" data-path="r-basics.html"><a href="r-basics.html#data-sets"><i class="fa fa-check"></i><b>2.15</b> Data sets</a></li>
<li class="chapter" data-level="2.16" data-path="r-basics.html"><a href="r-basics.html#cheatsheet"><i class="fa fa-check"></i><b>2.16</b> Cheatsheet</a></li>
<li class="chapter" data-level="2.17" data-path="r-basics.html"><a href="r-basics.html#problems"><i class="fa fa-check"></i><b>2.17</b> Problems</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="univariat-data.html"><a href="univariat-data.html"><i class="fa fa-check"></i><b>3</b> Univariat data</a>
<ul>
<li class="chapter" data-level="3.1" data-path="univariat-data.html"><a href="univariat-data.html#introduction-2"><i class="fa fa-check"></i><b>3.1</b> Introduction 2</a></li>
<li class="chapter" data-level="3.2" data-path="univariat-data.html"><a href="univariat-data.html#data-vectors"><i class="fa fa-check"></i><b>3.2</b> Data vectors</a></li>
<li class="chapter" data-level="3.3" data-path="univariat-data.html"><a href="univariat-data.html#data-type"><i class="fa fa-check"></i><b>3.3</b> Data type</a></li>
<li class="chapter" data-level="3.4" data-path="univariat-data.html"><a href="univariat-data.html#functions-2"><i class="fa fa-check"></i><b>3.4</b> Functions 2</a></li>
<li class="chapter" data-level="3.5" data-path="univariat-data.html"><a href="univariat-data.html#miscellaneous-1"><i class="fa fa-check"></i><b>3.5</b> Miscellaneous 1</a></li>
<li class="chapter" data-level="3.6" data-path="univariat-data.html"><a href="univariat-data.html#numeric-summaries"><i class="fa fa-check"></i><b>3.6</b> Numeric summaries</a></li>
<li class="chapter" data-level="3.7" data-path="univariat-data.html"><a href="univariat-data.html#center-for-a-univariat-variable"><i class="fa fa-check"></i><b>3.7</b> Center for a univariat variable</a>
<ul>
<li class="chapter" data-level="3.7.1" data-path="univariat-data.html"><a href="univariat-data.html#sample-mean"><i class="fa fa-check"></i><b>3.7.1</b> Sample mean</a></li>
<li class="chapter" data-level="3.7.2" data-path="univariat-data.html"><a href="univariat-data.html#measure-of-position"><i class="fa fa-check"></i><b>3.7.2</b> Measure of Position</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="univariat-data.html"><a href="univariat-data.html#spread-for-a-univariat-variable"><i class="fa fa-check"></i><b>3.8</b> Spread for a univariat variable</a></li>
<li class="chapter" data-level="3.9" data-path="univariat-data.html"><a href="univariat-data.html#problems-02"><i class="fa fa-check"></i><b>3.9</b> Problems 02</a></li>
<li class="chapter" data-level="3.10" data-path="univariat-data.html"><a href="univariat-data.html#shape-for-a-univariat-variable"><i class="fa fa-check"></i><b>3.10</b> Shape for a univariat variable</a></li>
<li class="chapter" data-level="3.11" data-path="univariat-data.html"><a href="univariat-data.html#viewing-the-shape"><i class="fa fa-check"></i><b>3.11</b> Viewing the shape</a>
<ul>
<li class="chapter" data-level="3.11.1" data-path="univariat-data.html"><a href="univariat-data.html#histogram"><i class="fa fa-check"></i><b>3.11.1</b> Histogram</a></li>
<li class="chapter" data-level="3.11.2" data-path="univariat-data.html"><a href="univariat-data.html#density-plots"><i class="fa fa-check"></i><b>3.11.2</b> Density plots</a></li>
<li class="chapter" data-level="3.11.3" data-path="univariat-data.html"><a href="univariat-data.html#boxplots"><i class="fa fa-check"></i><b>3.11.3</b> Boxplots</a></li>
</ul></li>
<li class="chapter" data-level="3.12" data-path="univariat-data.html"><a href="univariat-data.html#quantile-graph"><i class="fa fa-check"></i><b>3.12</b> Quantile graph</a></li>
<li class="chapter" data-level="3.13" data-path="univariat-data.html"><a href="univariat-data.html#categorical-data"><i class="fa fa-check"></i><b>3.13</b> Categorical data</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="bivariate-data.html"><a href="bivariate-data.html"><i class="fa fa-check"></i><b>4</b> Bivariate data</a>
<ul>
<li class="chapter" data-level="4.1" data-path="bivariate-data.html"><a href="bivariate-data.html#introduction-3"><i class="fa fa-check"></i><b>4.1</b> Introduction 3</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="bivariate-data.html"><a href="bivariate-data.html#independence-samples"><i class="fa fa-check"></i><b>4.1.1</b> Independence samples</a></li>
<li class="chapter" data-level="4.1.2" data-path="bivariate-data.html"><a href="bivariate-data.html#plot"><i class="fa fa-check"></i><b>4.1.2</b> plot</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="bivariate-data.html"><a href="bivariate-data.html#data-manipulation"><i class="fa fa-check"></i><b>4.2</b> Data manipulation</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="bivariate-data.html"><a href="bivariate-data.html#list"><i class="fa fa-check"></i><b>4.2.1</b> List</a></li>
<li class="chapter" data-level="4.2.2" data-path="bivariate-data.html"><a href="bivariate-data.html#data-frame"><i class="fa fa-check"></i><b>4.2.2</b> Data frame</a></li>
<li class="chapter" data-level="4.2.3" data-path="bivariate-data.html"><a href="bivariate-data.html#model-formulas"><i class="fa fa-check"></i><b>4.2.3</b> Model formulas</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="bivariate-data.html"><a href="bivariate-data.html#paired-data"><i class="fa fa-check"></i><b>4.3</b> Paired data</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="bivariate-data.html"><a href="bivariate-data.html#pearson-correlation"><i class="fa fa-check"></i><b>4.3.1</b> Pearson Correlation</a></li>
<li class="chapter" data-level="4.3.2" data-path="bivariate-data.html"><a href="bivariate-data.html#spearman-correlation-coefficient"><i class="fa fa-check"></i><b>4.3.2</b> Spearman correlation coefficient</a></li>
<li class="chapter" data-level="4.3.3" data-path="bivariate-data.html"><a href="bivariate-data.html#correlation-causation-and-association"><i class="fa fa-check"></i><b>4.3.3</b> Correlation, causation and association</a></li>
<li class="chapter" data-level="4.3.4" data-path="bivariate-data.html"><a href="bivariate-data.html#trends"><i class="fa fa-check"></i><b>4.3.4</b> Trends</a></li>
<li class="chapter" data-level="4.3.5" data-path="bivariate-data.html"><a href="bivariate-data.html#the-method-of-least-squares"><i class="fa fa-check"></i><b>4.3.5</b> The method of least squares</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="bivariate-data.html"><a href="bivariate-data.html#problems-03"><i class="fa fa-check"></i><b>4.4</b> Problems 03</a></li>
<li class="chapter" data-level="4.5" data-path="bivariate-data.html"><a href="bivariate-data.html#bivariate-categorical-data"><i class="fa fa-check"></i><b>4.5</b> Bivariate categorical data</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="bivariate-data.html"><a href="bivariate-data.html#contingency-tables"><i class="fa fa-check"></i><b>4.5.1</b> Contingency tables</a></li>
<li class="chapter" data-level="4.5.2" data-path="bivariate-data.html"><a href="bivariate-data.html#marginal-distributions"><i class="fa fa-check"></i><b>4.5.2</b> Marginal distributions</a></li>
<li class="chapter" data-level="4.5.3" data-path="bivariate-data.html"><a href="bivariate-data.html#conditional-distributions"><i class="fa fa-check"></i><b>4.5.3</b> Conditional distributions</a></li>
<li class="chapter" data-level="4.5.4" data-path="bivariate-data.html"><a href="bivariate-data.html#graphical-summaries-of-contingency-tables"><i class="fa fa-check"></i><b>4.5.4</b> Graphical summaries of contingency tables</a></li>
<li class="chapter" data-level="4.5.5" data-path="bivariate-data.html"><a href="bivariate-data.html#measures-of-association-for-categorical-data"><i class="fa fa-check"></i><b>4.5.5</b> Measures of association for categorical data</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="bivariate-data.html"><a href="bivariate-data.html#problems-04"><i class="fa fa-check"></i><b>4.6</b> Problems 04</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="data-transformation-basics.html"><a href="data-transformation-basics.html"><i class="fa fa-check"></i><b>5</b> Data transformation basics</a>
<ul>
<li class="chapter" data-level="5.1" data-path="data-transformation-basics.html"><a href="data-transformation-basics.html#data-structures-in-r"><i class="fa fa-check"></i><b>5.1</b> Data structures in R</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="data-transformation-basics.html"><a href="data-transformation-basics.html#vectors"><i class="fa fa-check"></i><b>5.1.1</b> Vectors</a></li>
<li class="chapter" data-level="5.1.2" data-path="data-transformation-basics.html"><a href="data-transformation-basics.html#lists"><i class="fa fa-check"></i><b>5.1.2</b> Lists</a></li>
<li class="chapter" data-level="5.1.3" data-path="data-transformation-basics.html"><a href="data-transformation-basics.html#matrices"><i class="fa fa-check"></i><b>5.1.3</b> Matrices</a></li>
<li class="chapter" data-level="5.1.4" data-path="data-transformation-basics.html"><a href="data-transformation-basics.html#data.frame"><i class="fa fa-check"></i><b>5.1.4</b> data.frame</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="data-transformation-basics.html"><a href="data-transformation-basics.html#subset"><i class="fa fa-check"></i><b>5.2</b> subset</a></li>
<li class="chapter" data-level="5.3" data-path="data-transformation-basics.html"><a href="data-transformation-basics.html#merging-and-split"><i class="fa fa-check"></i><b>5.3</b> merging and split</a></li>
<li class="chapter" data-level="5.4" data-path="data-transformation-basics.html"><a href="data-transformation-basics.html#transforming-data"><i class="fa fa-check"></i><b>5.4</b> transforming data</a></li>
<li class="chapter" data-level="5.5" data-path="data-transformation-basics.html"><a href="data-transformation-basics.html#analysis-example-babies"><i class="fa fa-check"></i><b>5.5</b> Analysis example (babies)</a></li>
<li class="chapter" data-level="5.6" data-path="data-transformation-basics.html"><a href="data-transformation-basics.html#apply"><i class="fa fa-check"></i><b>5.6</b> apply</a></li>
<li class="chapter" data-level="5.7" data-path="data-transformation-basics.html"><a href="data-transformation-basics.html#problems-05"><i class="fa fa-check"></i><b>5.7</b> Problems 05</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="multivariate-tydiverse.html"><a href="multivariate-tydiverse.html"><i class="fa fa-check"></i><b>6</b> Multivariate (tydiverse)</a>
<ul>
<li class="chapter" data-level="6.1" data-path="multivariate-tydiverse.html"><a href="multivariate-tydiverse.html#tidy-data-structure"><i class="fa fa-check"></i><b>6.1</b> Tidy data structure</a></li>
<li class="chapter" data-level="6.2" data-path="multivariate-tydiverse.html"><a href="multivariate-tydiverse.html#data-manipulation-with-dplyr"><i class="fa fa-check"></i><b>6.2</b> Data manipulation with dplyr</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="multivariate-tydiverse.html"><a href="multivariate-tydiverse.html#dplyr---pipe-operator"><i class="fa fa-check"></i><b>6.2.1</b> dplyr - pipe operator</a></li>
<li class="chapter" data-level="6.2.2" data-path="multivariate-tydiverse.html"><a href="multivariate-tydiverse.html#dplyr---important-functions"><i class="fa fa-check"></i><b>6.2.2</b> dplyr - Important functions</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="multivariate-tydiverse.html"><a href="multivariate-tydiverse.html#code-comparison"><i class="fa fa-check"></i><b>6.3</b> code comparison</a></li>
<li class="chapter" data-level="6.4" data-path="multivariate-tydiverse.html"><a href="multivariate-tydiverse.html#dplyr-example-iris"><i class="fa fa-check"></i><b>6.4</b> dplyr example iris</a></li>
<li class="chapter" data-level="6.5" data-path="multivariate-tydiverse.html"><a href="multivariate-tydiverse.html#problems-06"><i class="fa fa-check"></i><b>6.5</b> Problems 06</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="populations.html"><a href="populations.html"><i class="fa fa-check"></i><b>7</b> Populations</a>
<ul>
<li class="chapter" data-level="7.1" data-path="populations.html"><a href="populations.html#random-variable"><i class="fa fa-check"></i><b>7.1</b> Random variable</a></li>
<li class="chapter" data-level="7.2" data-path="populations.html"><a href="populations.html#discrete-random-variable"><i class="fa fa-check"></i><b>7.2</b> Discrete random variable</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="populations.html"><a href="populations.html#probability-mass-function"><i class="fa fa-check"></i><b>7.2.1</b> Probability mass function</a></li>
<li class="chapter" data-level="7.2.2" data-path="populations.html"><a href="populations.html#mean-and-standard-deviation-of-discrete-r.v."><i class="fa fa-check"></i><b>7.2.2</b> Mean and standard deviation of discrete R.V.</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="populations.html"><a href="populations.html#continuous-random-variable"><i class="fa fa-check"></i><b>7.3</b> Continuous random variable</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="populations.html"><a href="populations.html#probability-density-function"><i class="fa fa-check"></i><b>7.3.1</b> Probability density function</a></li>
<li class="chapter" data-level="7.3.2" data-path="populations.html"><a href="populations.html#mean-and-standard-deviation-of-continuous-r.v."><i class="fa fa-check"></i><b>7.3.2</b> Mean and standard deviation of continuous R.V.</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="populations.html"><a href="populations.html#sampling-from-a-population"><i class="fa fa-check"></i><b>7.4</b> Sampling from a population</a></li>
<li class="chapter" data-level="7.5" data-path="populations.html"><a href="populations.html#problems-07"><i class="fa fa-check"></i><b>7.5</b> Problems 07</a></li>
<li class="chapter" data-level="7.6" data-path="populations.html"><a href="populations.html#sampling-distribution"><i class="fa fa-check"></i><b>7.6</b> Sampling distribution</a></li>
<li class="chapter" data-level="7.7" data-path="populations.html"><a href="populations.html#probability-distributions"><i class="fa fa-check"></i><b>7.7</b> Probability distributions</a>
<ul>
<li class="chapter" data-level="7.7.1" data-path="populations.html"><a href="populations.html#bernoulli-random-variables"><i class="fa fa-check"></i><b>7.7.1</b> Bernoulli random variables</a></li>
<li class="chapter" data-level="7.7.2" data-path="populations.html"><a href="populations.html#binomial-random-variables"><i class="fa fa-check"></i><b>7.7.2</b> Binomial random variables</a></li>
<li class="chapter" data-level="7.7.3" data-path="populations.html"><a href="populations.html#normal-random-variables"><i class="fa fa-check"></i><b>7.7.3</b> Normal random variables</a></li>
<li class="chapter" data-level="7.7.4" data-path="populations.html"><a href="populations.html#uniform-distribution"><i class="fa fa-check"></i><b>7.7.4</b> Uniform distribution</a></li>
<li class="chapter" data-level="7.7.5" data-path="populations.html"><a href="populations.html#poisson-distribution"><i class="fa fa-check"></i><b>7.7.5</b> Poisson distribution</a></li>
<li class="chapter" data-level="7.7.6" data-path="populations.html"><a href="populations.html#exponential-distribution"><i class="fa fa-check"></i><b>7.7.6</b> Exponential distribution</a></li>
<li class="chapter" data-level="7.7.7" data-path="populations.html"><a href="populations.html#sampling-distributions"><i class="fa fa-check"></i><b>7.7.7</b> Sampling distributions</a></li>
</ul></li>
<li class="chapter" data-level="7.8" data-path="populations.html"><a href="populations.html#problems-07-2"><i class="fa fa-check"></i><b>7.8</b> Problems 07-2</a></li>
<li class="chapter" data-level="7.9" data-path="populations.html"><a href="populations.html#the-central-limit-theorem"><i class="fa fa-check"></i><b>7.9</b> The central limit theorem</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="statistical-inference.html"><a href="statistical-inference.html"><i class="fa fa-check"></i><b>8</b> Statistical inference</a>
<ul>
<li class="chapter" data-level="8.1" data-path="statistical-inference.html"><a href="statistical-inference.html#introduction"><i class="fa fa-check"></i><b>8.1</b> Introduction</a></li>
<li class="chapter" data-level="8.2" data-path="statistical-inference.html"><a href="statistical-inference.html#simulation"><i class="fa fa-check"></i><b>8.2</b> Simulation</a></li>
<li class="chapter" data-level="8.3" data-path="statistical-inference.html"><a href="statistical-inference.html#z-statistics-with-simulation"><i class="fa fa-check"></i><b>8.3</b> z-statistics with simulation</a></li>
<li class="chapter" data-level="8.4" data-path="statistical-inference.html"><a href="statistical-inference.html#t-statistics"><i class="fa fa-check"></i><b>8.4</b> t-statistics</a></li>
<li class="chapter" data-level="8.5" data-path="statistical-inference.html"><a href="statistical-inference.html#two-sample-significance-tests"><i class="fa fa-check"></i><b>8.5</b> Two sample significance tests</a></li>
<li class="chapter" data-level="8.6" data-path="statistical-inference.html"><a href="statistical-inference.html#estimation-and-confidence-interval"><i class="fa fa-check"></i><b>8.6</b> Estimation and confidence interval</a></li>
<li class="chapter" data-level="8.7" data-path="statistical-inference.html"><a href="statistical-inference.html#bootstrap"><i class="fa fa-check"></i><b>8.7</b> Bootstrap</a></li>
<li class="chapter" data-level="8.8" data-path="statistical-inference.html"><a href="statistical-inference.html#problem-08"><i class="fa fa-check"></i><b>8.8</b> Problem 08</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="confidence-intervals.html"><a href="confidence-intervals.html"><i class="fa fa-check"></i><b>9</b> Confidence intervals</a>
<ul>
<li class="chapter" data-level="9.1" data-path="confidence-intervals.html"><a href="confidence-intervals.html#ci-for-population-proportion-p"><i class="fa fa-check"></i><b>9.1</b> CI for population proportion, <span class="math inline">\(p\)</span></a></li>
<li class="chapter" data-level="9.2" data-path="confidence-intervals.html"><a href="confidence-intervals.html#ci-for-population-mean"><i class="fa fa-check"></i><b>9.2</b> CI for population mean</a></li>
<li class="chapter" data-level="9.3" data-path="confidence-intervals.html"><a href="confidence-intervals.html#ci-for-the-differences"><i class="fa fa-check"></i><b>9.3</b> CI for the differences</a></li>
<li class="chapter" data-level="9.4" data-path="confidence-intervals.html"><a href="confidence-intervals.html#problem-09"><i class="fa fa-check"></i><b>9.4</b> Problem 09</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="significance-test.html"><a href="significance-test.html"><i class="fa fa-check"></i><b>10</b> Significance test</a>
<ul>
<li class="chapter" data-level="10.1" data-path="significance-test.html"><a href="significance-test.html#errors-in-significance-tests"><i class="fa fa-check"></i><b>10.1</b> Errors in significance tests</a></li>
<li class="chapter" data-level="10.2" data-path="significance-test.html"><a href="significance-test.html#significance-test-for-a-population-proportion"><i class="fa fa-check"></i><b>10.2</b> Significance test for a population proportion</a></li>
<li class="chapter" data-level="10.3" data-path="significance-test.html"><a href="significance-test.html#significance-test-for-the-mean-t-test"><i class="fa fa-check"></i><b>10.3</b> Significance test for the mean (t-test)</a></li>
<li class="chapter" data-level="10.4" data-path="significance-test.html"><a href="significance-test.html#problem-10"><i class="fa fa-check"></i><b>10.4</b> Problem 10</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="goodness-of-fit.html"><a href="goodness-of-fit.html"><i class="fa fa-check"></i><b>11</b> Goodness of fit</a>
<ul>
<li class="chapter" data-level="11.1" data-path="goodness-of-fit.html"><a href="goodness-of-fit.html#the-chi-squared-goodness-of-fit-test"><i class="fa fa-check"></i><b>11.1</b> The chi-squared goodness-of-fit test</a></li>
<li class="chapter" data-level="11.2" data-path="goodness-of-fit.html"><a href="goodness-of-fit.html#the-chi-square-test-of-independence"><i class="fa fa-check"></i><b>11.2</b> The chi-square test of independence</a></li>
<li class="chapter" data-level="11.3" data-path="goodness-of-fit.html"><a href="goodness-of-fit.html#goodness-of-fit-tests-for-continuous-distribution"><i class="fa fa-check"></i><b>11.3</b> Goodness-of-fit tests for continuous distribution</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">R로 배우는 기초통계</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="statistical-inference" class="section level1">
<h1><span class="header-section-number">Chapter 8</span> Statistical inference</h1>
<ul>
<li><a href="https://youtu.be/rVdZJx0wRVk" class="uri">https://youtu.be/rVdZJx0wRVk</a></li>
</ul>
<div id="introduction" class="section level2">
<h2><span class="header-section-number">8.1</span> Introduction</h2>
<p>통계적 추정이란 모집단으로부터 임의 추출된 표본을 이용하여 모집단을 추정하는 과정을 의미합니다. 앞에서 배운들 중 다음 중요한 키워드들이 있습니다. 복습하는 의미에서 각 키워드들의 의미를 다시 한 번 익혀두시기 바랍니다.</p>
<ul>
<li>모집단 (population) - 전체 대상</li>
<li>모수 (Parameter) - 모집단의 분포를 설명하는 대푯값</li>
<li>표본 (sample) - 모집단으로부터 임의 추출된 관측값의 모음</li>
<li>통계량 (statistics) - 표본의 평균, 분산과 같은 대푯값으로 표본의 특징을 수치화한 값</li>
<li>확률변수 (random variable) - 확률적으로 따라 값이 결정되는 변수</li>
<li>확률분포 및 확률 질량/밀도 함수<br />
</li>
<li>표본분포 (sampling distribution) - 통계량의 분포</li>
</ul>
<p>다음은 표준정규분포 모집단에서 (모수: <span class="math inline">\(\mu=0, \sigma=1\)</span>) 16개 표본을 임의 추출하여 평균을 (통계량) <span class="math inline">\(\bar{x}\)</span> 구하고 이 과정을 10번 반복한 상황을 표현한 그림으로 통계적 추론의 과정을 보여 줍니다. 즉, 표본을 뽑고 그 평균을 (표본평균) 구하는 과정을 반복할 경우 표본평균의 평균이 모평균에 수렴하고 표본평균의 분산이 표본들의 분산보다 더 작다는 것을 보여줍니다.</p>
<div class="figure">
<img src="images/08/01.png" alt="" />
<p class="caption">UsingR for introductory statistics, 243 페이지, 동그라미: 표본 <span class="math inline">\(x\)</span>, 사각형: 표본평균 <span class="math inline">\(\bar{x}\)</span>, 점선:모평균 (<span class="math inline">\(\mu\)</span>), 하단 밀도 그래프: 표본평균의 분포</p>
</div>
<ul>
<li>어떤 임의 표본에 대해서 <span class="math inline">\(\bar{x}\)</span>의 표본분포는 <span class="math inline">\(\mu\)</span> 근처에 위치</li>
<li>어떤 임의 표본에 대해서 <span class="math inline">\(\bar{x}\)</span>의 표본분포의 표준편차는 <span class="math inline">\(\sigma/\sqrt{n}\)</span> 로 표현 (<span class="math inline">\(\sigma\)</span>는 모분산, 표본들의 분산보다 작음)</li>
<li>모분포가 정규분포이면 <span class="math inline">\(\bar{x}\)</span>도 정규분포임</li>
</ul>
</div>
<div id="simulation" class="section level2">
<h2><span class="header-section-number">8.2</span> Simulation</h2>
<p>이번 장에서는 시뮬레이션을 통해 추정의 개념을 이해하는 것을 목적으로 합니다. 확률과 공식의 유도를 통한 추정과정의 이해도 중요하지만 컴퓨팅 기반의 시뮬레이션도 통계적 추정의 개념을 이해하는데 큰 도움이 될 수 있습니다. R에서 분포관련한 시뮬레이션은 앞서 소개한 <code>d</code>, <code>r</code>, <code>p</code>, <code>q</code> 함수를 이용할 수 있습니다.</p>
<p><strong>[EXERCISE]</strong> <span class="math inline">\(N(0, 1)\)</span>의 분포를 <code>dnorm()</code>을 이용해 그리시오 (<span class="math inline">\(-4 \le x \le 4\)</span>)</p>
<div class="sourceCode" id="cb176"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb176-1"><a href="statistical-inference.html#cb176-1"></a><span class="kw">library</span>(tidyverse)</span>
<span id="cb176-2"><a href="statistical-inference.html#cb176-2"></a></span>
<span id="cb176-3"><a href="statistical-inference.html#cb176-3"></a>x &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="op">-</span><span class="dv">4</span>, <span class="dv">4</span>, <span class="dt">by=</span><span class="fl">0.01</span>)</span>
<span id="cb176-4"><a href="statistical-inference.html#cb176-4"></a>y &lt;-<span class="st"> </span><span class="kw">dnorm</span>(x, <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb176-5"><a href="statistical-inference.html#cb176-5"></a>dat &lt;-<span class="st"> </span><span class="kw">data.frame</span>(x, y)</span>
<span id="cb176-6"><a href="statistical-inference.html#cb176-6"></a><span class="kw">ggplot</span>(dat, <span class="kw">aes</span>(x, y)) <span class="op">+</span></span>
<span id="cb176-7"><a href="statistical-inference.html#cb176-7"></a><span class="st">  </span><span class="kw">geom_line</span>()</span></code></pre></div>
<p>지수분포의 경우, 파라미터 (<span class="math inline">\(\lambda\)</span>) 값에 따른 그래프 변화</p>
<div class="sourceCode" id="cb177"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb177-1"><a href="statistical-inference.html#cb177-1"></a>x &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">4</span>, <span class="dt">by=</span><span class="fl">0.01</span>)</span>
<span id="cb177-2"><a href="statistical-inference.html#cb177-2"></a>y1 &lt;-<span class="st"> </span><span class="kw">dexp</span>(x, <span class="dv">1</span>)</span>
<span id="cb177-3"><a href="statistical-inference.html#cb177-3"></a>y2 &lt;-<span class="st"> </span><span class="kw">dexp</span>(x, <span class="dv">2</span>)</span>
<span id="cb177-4"><a href="statistical-inference.html#cb177-4"></a>y3 &lt;-<span class="st"> </span><span class="kw">dexp</span>(x, <span class="dv">3</span>)</span>
<span id="cb177-5"><a href="statistical-inference.html#cb177-5"></a>dat &lt;-<span class="st"> </span><span class="kw">data.frame</span>(x, y1, y2, y3)</span>
<span id="cb177-6"><a href="statistical-inference.html#cb177-6"></a>datlong &lt;-<span class="st"> </span>dat <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">pivot_longer</span>(<span class="dt">cols=</span><span class="kw">c</span>(y1, y2, y3))</span>
<span id="cb177-7"><a href="statistical-inference.html#cb177-7"></a><span class="kw">ggplot</span>(datlong, <span class="kw">aes</span>(<span class="dt">x=</span>x, <span class="dt">y=</span>value, <span class="dt">col=</span>name)) <span class="op">+</span></span>
<span id="cb177-8"><a href="statistical-inference.html#cb177-8"></a><span class="st">  </span><span class="kw">geom_line</span>(<span class="dt">size=</span><span class="dv">2</span>)</span></code></pre></div>
<p>아래 예제는 본 장의 처음 그림을 구현하는 코드 입니다. 각자 실행해 보시고 통계적 추론의 개념과 함께 그래프를 그리는 ggplot 코드도 익혀보시기 바랍니다.</p>
<p><strong>[EXERCISE]</strong> 표준정규분포로부터 16개의 표본을 뽑아 평균을 구하고 각 표본과 평균 값들을 <span class="math inline">\(y=1\)</span> 위치에 점으로 표현하시오 (<code>rnorm()</code>사용)</p>
<div class="sourceCode" id="cb178"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb178-1"><a href="statistical-inference.html#cb178-1"></a>nsample &lt;-<span class="st"> </span><span class="dv">16</span></span>
<span id="cb178-2"><a href="statistical-inference.html#cb178-2"></a>x &lt;-<span class="st"> </span><span class="kw">rnorm</span>(nsample, <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb178-3"><a href="statistical-inference.html#cb178-3"></a>y &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="dv">1</span>, nsample)</span>
<span id="cb178-4"><a href="statistical-inference.html#cb178-4"></a>xbar &lt;-<span class="st"> </span><span class="kw">mean</span>(x)</span>
<span id="cb178-5"><a href="statistical-inference.html#cb178-5"></a>dat &lt;-<span class="st"> </span><span class="kw">data.frame</span>(x, y)</span>
<span id="cb178-6"><a href="statistical-inference.html#cb178-6"></a><span class="kw">ggplot</span>(dat, <span class="kw">aes</span>(x, y)) <span class="op">+</span></span>
<span id="cb178-7"><a href="statistical-inference.html#cb178-7"></a><span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span></span>
<span id="cb178-8"><a href="statistical-inference.html#cb178-8"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">x=</span><span class="kw">mean</span>(x), <span class="dt">y=</span><span class="dv">1</span>), <span class="dt">colour=</span><span class="st">&quot;blue&quot;</span>, <span class="dt">size=</span><span class="dv">5</span>, <span class="dt">shape=</span><span class="dv">15</span>)</span></code></pre></div>
<p><strong>[EXERCISE]</strong> 위 예제와 같이 표준정규분포로부터 16개의 표본을 뽑아 평균을 구하는 과정을 두 번 반복하되 두 번째 데이터는 <span class="math inline">\(y=0.9\)</span> 위치에 표현하시오</p>
<div class="sourceCode" id="cb179"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb179-1"><a href="statistical-inference.html#cb179-1"></a>nsample &lt;-<span class="st"> </span><span class="dv">16</span></span>
<span id="cb179-2"><a href="statistical-inference.html#cb179-2"></a>x &lt;-<span class="st"> </span><span class="kw">rnorm</span>(nsample<span class="op">*</span><span class="dv">2</span>, <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb179-3"><a href="statistical-inference.html#cb179-3"></a>y &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="kw">rep</span>(<span class="dv">1</span>, nsample), <span class="kw">rep</span>(<span class="fl">0.9</span>, nsample))</span>
<span id="cb179-4"><a href="statistical-inference.html#cb179-4"></a>g &lt;-<span class="st"> </span><span class="kw">factor</span>(<span class="kw">c</span>(<span class="kw">rep</span>(<span class="dv">1</span>, nsample), <span class="kw">rep</span>(<span class="dv">2</span>, nsample)))</span>
<span id="cb179-5"><a href="statistical-inference.html#cb179-5"></a>dat &lt;-<span class="st"> </span><span class="kw">data.frame</span>(x, y, g)</span>
<span id="cb179-6"><a href="statistical-inference.html#cb179-6"></a></span>
<span id="cb179-7"><a href="statistical-inference.html#cb179-7"></a><span class="kw">ggplot</span>(dat, <span class="kw">aes</span>(x, y)) <span class="op">+</span></span>
<span id="cb179-8"><a href="statistical-inference.html#cb179-8"></a><span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span></span>
<span id="cb179-9"><a href="statistical-inference.html#cb179-9"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">x=</span><span class="kw">mean</span>(x[<span class="dv">1</span><span class="op">:</span>nsample]), <span class="dt">y=</span><span class="dv">1</span>), <span class="dt">colour=</span><span class="st">&quot;blue&quot;</span>, <span class="dt">size=</span><span class="dv">5</span>, <span class="dt">shape=</span><span class="dv">15</span>) <span class="op">+</span></span>
<span id="cb179-10"><a href="statistical-inference.html#cb179-10"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">x=</span><span class="kw">mean</span>(x[(nsample<span class="op">+</span><span class="dv">1</span>)<span class="op">:</span><span class="kw">length</span>(x)]), <span class="dt">y=</span><span class="fl">0.9</span>), <span class="dt">colour=</span><span class="st">&quot;blue&quot;</span>, <span class="dt">size=</span><span class="dv">5</span>, <span class="dt">shape=</span><span class="dv">15</span>) <span class="op">+</span></span>
<span id="cb179-11"><a href="statistical-inference.html#cb179-11"></a><span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="dt">limits=</span><span class="kw">c</span>(<span class="dv">0</span>, <span class="fl">1.2</span>))</span></code></pre></div>
<p><strong>[EXERCISE]</strong> 위 예제를 10번 반복하되 각 반복 데이터는 각각 <span class="math inline">\(y=1, 0.9, 0.8, ..., 0.1\)</span> 위치에 그리시오</p>
<div class="sourceCode" id="cb180"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb180-1"><a href="statistical-inference.html#cb180-1"></a>nsample &lt;-<span class="st"> </span><span class="dv">16</span></span>
<span id="cb180-2"><a href="statistical-inference.html#cb180-2"></a>nrep &lt;-<span class="st"> </span><span class="dv">10</span></span>
<span id="cb180-3"><a href="statistical-inference.html#cb180-3"></a></span>
<span id="cb180-4"><a href="statistical-inference.html#cb180-4"></a>x &lt;-<span class="st"> </span><span class="kw">rnorm</span>(nsample<span class="op">*</span>nrep, <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb180-5"><a href="statistical-inference.html#cb180-5"></a>tmpy &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="fl">0.1</span>, <span class="dv">1</span>, <span class="dt">length.out=</span>nrep)</span>
<span id="cb180-6"><a href="statistical-inference.html#cb180-6"></a>y &lt;-<span class="st"> </span><span class="kw">rep</span>(tmpy, <span class="dt">each=</span>nsample)</span>
<span id="cb180-7"><a href="statistical-inference.html#cb180-7"></a><span class="co">## ?rep</span></span>
<span id="cb180-8"><a href="statistical-inference.html#cb180-8"></a>g &lt;-<span class="st"> </span><span class="kw">factor</span>(y)</span>
<span id="cb180-9"><a href="statistical-inference.html#cb180-9"></a></span>
<span id="cb180-10"><a href="statistical-inference.html#cb180-10"></a>dat &lt;-<span class="st"> </span><span class="kw">data.frame</span>(x, y, g)</span>
<span id="cb180-11"><a href="statistical-inference.html#cb180-11"></a><span class="kw">head</span>(dat)</span>
<span id="cb180-12"><a href="statistical-inference.html#cb180-12"></a><span class="co">## sample means</span></span>
<span id="cb180-13"><a href="statistical-inference.html#cb180-13"></a>dat_mean &lt;-<span class="st"> </span>dat <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb180-14"><a href="statistical-inference.html#cb180-14"></a><span class="st">  </span><span class="kw">group_by</span>(g) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb180-15"><a href="statistical-inference.html#cb180-15"></a><span class="st">  </span><span class="kw">summarise</span>(<span class="dt">mean=</span><span class="kw">mean</span>(x))</span>
<span id="cb180-16"><a href="statistical-inference.html#cb180-16"></a><span class="kw">head</span>(dat_mean)</span>
<span id="cb180-17"><a href="statistical-inference.html#cb180-17"></a></span>
<span id="cb180-18"><a href="statistical-inference.html#cb180-18"></a><span class="kw">ggplot</span>() <span class="op">+</span><span class="st"> </span></span>
<span id="cb180-19"><a href="statistical-inference.html#cb180-19"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">data=</span>dat, <span class="kw">aes</span>(x, y)) <span class="op">+</span></span>
<span id="cb180-20"><a href="statistical-inference.html#cb180-20"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">data=</span>dat_mean, </span>
<span id="cb180-21"><a href="statistical-inference.html#cb180-21"></a>             <span class="kw">aes</span>(<span class="dt">x=</span>mean, <span class="dt">y=</span><span class="kw">as.numeric</span>(<span class="kw">as.character</span>(g))), </span>
<span id="cb180-22"><a href="statistical-inference.html#cb180-22"></a>             <span class="dt">colour=</span><span class="st">&quot;blue&quot;</span>, </span>
<span id="cb180-23"><a href="statistical-inference.html#cb180-23"></a>             <span class="dt">size=</span><span class="dv">5</span>, </span>
<span id="cb180-24"><a href="statistical-inference.html#cb180-24"></a>             <span class="dt">shape=</span><span class="dv">15</span>) <span class="op">+</span></span>
<span id="cb180-25"><a href="statistical-inference.html#cb180-25"></a><span class="st">  </span><span class="kw">theme_bw</span>()</span></code></pre></div>
<p><strong>[EXERCISE]</strong> 위 예제에서 사용된 샘플들의 정규분포 곡선과 <span class="math inline">\(\bar{x}\)</span>의 분포를 같이 그리시오 (<span class="math inline">\(-4 \le x \le 4\)</span>, 앞서 예제의 <code>dat</code>와 <code>dat_mean</code> 사용)</p>
<div class="sourceCode" id="cb181"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb181-1"><a href="statistical-inference.html#cb181-1"></a><span class="kw">head</span>(dat)</span>
<span id="cb181-2"><a href="statistical-inference.html#cb181-2"></a><span class="kw">head</span>(dat_mean)</span>
<span id="cb181-3"><a href="statistical-inference.html#cb181-3"></a></span>
<span id="cb181-4"><a href="statistical-inference.html#cb181-4"></a>x &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="op">-</span><span class="dv">4</span>, <span class="dv">4</span>, <span class="dt">by=</span><span class="fl">0.01</span>)</span>
<span id="cb181-5"><a href="statistical-inference.html#cb181-5"></a><span class="co"># distribution of the samples </span></span>
<span id="cb181-6"><a href="statistical-inference.html#cb181-6"></a>y &lt;-<span class="st"> </span><span class="kw">dnorm</span>(x, <span class="kw">mean</span>(dat<span class="op">$</span>x), <span class="kw">sd</span>(dat<span class="op">$</span>x))</span>
<span id="cb181-7"><a href="statistical-inference.html#cb181-7"></a><span class="co"># distribution of the sample means</span></span>
<span id="cb181-8"><a href="statistical-inference.html#cb181-8"></a>y2 &lt;-<span class="st"> </span><span class="kw">dnorm</span>(x, <span class="kw">mean</span>(dat_mean<span class="op">$</span>mean), <span class="kw">sd</span>(dat_mean<span class="op">$</span>mean))</span>
<span id="cb181-9"><a href="statistical-inference.html#cb181-9"></a>dat2 &lt;-<span class="st"> </span><span class="kw">data.frame</span>(x, y, y2)</span>
<span id="cb181-10"><a href="statistical-inference.html#cb181-10"></a>dat2_long &lt;-<span class="st"> </span>dat2 <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb181-11"><a href="statistical-inference.html#cb181-11"></a><span class="st">  </span><span class="kw">pivot_longer</span>(<span class="dt">cols=</span><span class="kw">c</span>(y, y2))</span>
<span id="cb181-12"><a href="statistical-inference.html#cb181-12"></a><span class="kw">head</span>(dat2_long)</span>
<span id="cb181-13"><a href="statistical-inference.html#cb181-13"></a></span>
<span id="cb181-14"><a href="statistical-inference.html#cb181-14"></a><span class="kw">ggplot</span>(dat2_long, <span class="kw">aes</span>(<span class="dt">x=</span>x, <span class="dt">y=</span>value, <span class="dt">color=</span>name)) <span class="op">+</span></span>
<span id="cb181-15"><a href="statistical-inference.html#cb181-15"></a><span class="st">  </span><span class="kw">geom_line</span>(<span class="dt">size=</span><span class="fl">1.2</span>) <span class="op">+</span></span>
<span id="cb181-16"><a href="statistical-inference.html#cb181-16"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">y=</span><span class="st">&quot;Density&quot;</span>) <span class="op">+</span></span>
<span id="cb181-17"><a href="statistical-inference.html#cb181-17"></a><span class="st">  </span><span class="kw">theme_bw</span>() <span class="op">+</span></span>
<span id="cb181-18"><a href="statistical-inference.html#cb181-18"></a><span class="st">  </span><span class="kw">scale_color_manual</span>(<span class="dt">name=</span><span class="st">&quot;Type&quot;</span>, </span>
<span id="cb181-19"><a href="statistical-inference.html#cb181-19"></a>                     <span class="dt">labels=</span><span class="kw">c</span>(<span class="st">&quot;Samples&quot;</span>, <span class="st">&quot;Sample Means&quot;</span>),</span>
<span id="cb181-20"><a href="statistical-inference.html#cb181-20"></a>                     <span class="dt">values=</span><span class="kw">c</span>(<span class="st">&quot;red&quot;</span>, <span class="st">&quot;blue&quot;</span>))</span></code></pre></div>
<p>위와 같이 표본들의 분포보다 표본평균들의 분포가 분포가 더 중심에 가깝다는 것을 볼 수 있습니다.</p>
</div>
<div id="z-statistics-with-simulation" class="section level2">
<h2><span class="header-section-number">8.3</span> z-statistics with simulation</h2>
<p>정규분포에서 추출된 표본들의 평균(표본평균)은 <span class="math inline">\(n\)</span>의 수가 많지 않더라도 정규분포를 따릅니다 (<span class="math inline">\(n\)</span>이 충분히 많은 경우, 중심극한정리에 의해서 모집단의 분포와 상관없이 표본평균의 분포는 정규분포 입니다). 통계적 유의성 판단의 기본 룰은 특정 확률변수 <span class="math inline">\(X\)</span>의 분포를 가정한 후에 특정 사건의 관측한 값이 <span class="math inline">\(X\)</span>의 확률분포 어디에 위치하는지 찾고 확률을 계산하여 해당 사건이 일어날만한 일이였으면 가정이 맞는 것으로 사건이 일어날 확률이 적게 나오면 가정이 틀린 것으로 판단하는 것입니다.</p>
<p>유사한 방법으로 모집단이 정규분포로 알려진 표본들을 가지고 표본평균을 구했을때 이 표본평균이 정규분포에서 어디에 위치하는지와 그 확률을 계산하여 관측한 표본평균의 유의성을 판단할 수 있습니다. 이 과정에 사용하는 통계량이 z-score (z값) 입니다. 관측값을 z-score로 변환해줄 경우 표준정규분포 (<span class="math inline">\(N(0, 1)\)</span>)로부터 확률을 쉽게 계산할 수 있습니다.</p>
<p><span class="math display">\[ 
z= \frac{\bar{x} - \mu}{(\sigma/\sqrt{n})}
\]</span></p>
<p>앞서 Univariate, Bivariate 학습에서 배웠던 Z-score는 표본에 대한 통계량으로 표준편차로 나누어준것과 달리 아래 z-score는 표본평균에 대한 z-score로서 모평균을 빼주고 모분산/<span class="math inline">\(\sqrt{n}\)</span> 값을 사용한 점이 다릅니다.</p>
<p><strong>[EXERCISE]</strong> A 제과 업체에는 그들이 생산하는 사탕의 평균 무게가 평균 100g이고 표준편차가 16인 정규분포를 따른다고 주장한다. 그런데 소비자들은 이 사탕의 평균 무게가 100g보다 낮다고 의심을 하고 표본 10개를 추출하고 평균을 구했더니 90g이 관측되었다. z-score를 계산하고 표준정규분포에서 위치를 표시하시오.</p>
<div class="sourceCode" id="cb182"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb182-1"><a href="statistical-inference.html#cb182-1"></a>zstat &lt;-<span class="st"> </span><span class="cf">function</span>(x, mu, sigma){</span>
<span id="cb182-2"><a href="statistical-inference.html#cb182-2"></a>  z &lt;-<span class="st"> </span>(<span class="kw">mean</span>(x)<span class="op">-</span>mu)<span class="op">/</span>(sigma<span class="op">/</span><span class="kw">sqrt</span>(<span class="kw">length</span>(x)))</span>
<span id="cb182-3"><a href="statistical-inference.html#cb182-3"></a>  <span class="kw">return</span>(z)</span>
<span id="cb182-4"><a href="statistical-inference.html#cb182-4"></a>}</span>
<span id="cb182-5"><a href="statistical-inference.html#cb182-5"></a></span>
<span id="cb182-6"><a href="statistical-inference.html#cb182-6"></a>xobs &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">90</span>, <span class="dv">75</span>, <span class="dv">89</span>, <span class="dv">103</span>, <span class="dv">95</span>, <span class="dv">110</span>, <span class="dv">73</span>, <span class="dv">93</span>, <span class="dv">92</span>, <span class="dv">80</span>)</span>
<span id="cb182-7"><a href="statistical-inference.html#cb182-7"></a>z &lt;-<span class="st"> </span><span class="kw">zstat</span>(xobs, <span class="dv">100</span>, <span class="dv">16</span>)</span>
<span id="cb182-8"><a href="statistical-inference.html#cb182-8"></a></span>
<span id="cb182-9"><a href="statistical-inference.html#cb182-9"></a></span>
<span id="cb182-10"><a href="statistical-inference.html#cb182-10"></a>x &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="op">-</span><span class="dv">5</span>, <span class="dv">5</span>, <span class="dt">length.out=</span><span class="dv">100</span>)</span>
<span id="cb182-11"><a href="statistical-inference.html#cb182-11"></a>y &lt;-<span class="st"> </span><span class="kw">dnorm</span>(x, <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb182-12"><a href="statistical-inference.html#cb182-12"></a><span class="co"># distribution of the sample means</span></span>
<span id="cb182-13"><a href="statistical-inference.html#cb182-13"></a>dat &lt;-<span class="st"> </span><span class="kw">data.frame</span>(x, y)</span>
<span id="cb182-14"><a href="statistical-inference.html#cb182-14"></a>p &lt;-<span class="st"> </span><span class="kw">ggplot</span>(dat, <span class="kw">aes</span>(<span class="dt">x=</span>x, <span class="dt">y=</span>y)) <span class="op">+</span></span>
<span id="cb182-15"><a href="statistical-inference.html#cb182-15"></a><span class="st">  </span><span class="kw">geom_area</span>(<span class="dt">data=</span><span class="kw">filter</span>(dat, x <span class="op">&lt;</span><span class="st"> </span>z), <span class="dt">fill=</span><span class="st">&quot;red&quot;</span>) <span class="op">+</span></span>
<span id="cb182-16"><a href="statistical-inference.html#cb182-16"></a><span class="st">  </span><span class="kw">geom_line</span>(<span class="dt">size=</span><span class="fl">1.2</span>) <span class="op">+</span></span>
<span id="cb182-17"><a href="statistical-inference.html#cb182-17"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">y=</span><span class="st">&quot;Density&quot;</span>) <span class="op">+</span></span>
<span id="cb182-18"><a href="statistical-inference.html#cb182-18"></a><span class="st">  </span><span class="kw">theme_bw</span>() <span class="op">+</span></span>
<span id="cb182-19"><a href="statistical-inference.html#cb182-19"></a><span class="st">  </span><span class="kw">geom_segment</span>(<span class="kw">aes</span>(<span class="dt">x=</span><span class="op">-</span><span class="dv">1</span>, <span class="dt">xend=</span>z, <span class="dt">y=</span><span class="fl">0.05</span>, <span class="dt">yend=</span><span class="dv">0</span>), </span>
<span id="cb182-20"><a href="statistical-inference.html#cb182-20"></a>               <span class="dt">arrow =</span> <span class="kw">arrow</span>(<span class="dt">length =</span> <span class="kw">unit</span>(<span class="fl">0.1</span>, <span class="st">&quot;inches&quot;</span>)), </span>
<span id="cb182-21"><a href="statistical-inference.html#cb182-21"></a>               <span class="dt">size=</span><span class="dv">1</span>) <span class="op">+</span></span>
<span id="cb182-22"><a href="statistical-inference.html#cb182-22"></a><span class="st">  </span><span class="kw">annotate</span>(<span class="st">&quot;text&quot;</span>, <span class="dt">label=</span><span class="kw">round</span>(z,<span class="dv">2</span>), <span class="dt">x=</span><span class="op">-</span><span class="fl">0.7</span>, <span class="dt">y=</span><span class="fl">0.07</span>) </span>
<span id="cb182-23"><a href="statistical-inference.html#cb182-23"></a>  </span>
<span id="cb182-24"><a href="statistical-inference.html#cb182-24"></a>p</span></code></pre></div>
<p>정규분포에서 관측값보다 더 작은 값이 관측될 확률 (<span class="math inline">\(p(\bar{X} &lt; 90)=p(Z&lt;-1.98)\)</span>)은 <code>pnorm</code> 함수를 사용해서 구할 수 있으며 시뮬레이션을 이용할 수도 있습니다.</p>
<div class="sourceCode" id="cb183"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb183-1"><a href="statistical-inference.html#cb183-1"></a>p <span class="op">+</span><span class="st"> </span><span class="kw">geom_segment</span>(<span class="kw">aes</span>(<span class="dt">x=</span><span class="op">-</span><span class="fl">2.2</span>, <span class="dt">xend=</span><span class="op">-</span><span class="fl">2.2</span>, <span class="dt">y=</span><span class="fl">0.1</span>, <span class="dt">yend=</span><span class="fl">0.01</span>), </span>
<span id="cb183-2"><a href="statistical-inference.html#cb183-2"></a>                 <span class="dt">arrow =</span> <span class="kw">arrow</span>(<span class="dt">length =</span> <span class="kw">unit</span>(<span class="fl">0.1</span>, <span class="st">&quot;inches&quot;</span>)),</span>
<span id="cb183-3"><a href="statistical-inference.html#cb183-3"></a>                 <span class="dt">size=</span><span class="dv">1</span>) <span class="op">+</span><span class="st"> </span></span>
<span id="cb183-4"><a href="statistical-inference.html#cb183-4"></a><span class="st">  </span><span class="kw">annotate</span>(<span class="st">&quot;text&quot;</span>, <span class="dt">label=</span><span class="kw">round</span>(<span class="kw">pnorm</span>(z, <span class="dv">0</span>, <span class="dv">1</span>),<span class="dv">3</span>), <span class="dt">x=</span><span class="op">-</span><span class="fl">2.2</span>, <span class="dt">y=</span><span class="fl">0.12</span>)</span>
<span id="cb183-5"><a href="statistical-inference.html#cb183-5"></a></span>
<span id="cb183-6"><a href="statistical-inference.html#cb183-6"></a></span>
<span id="cb183-7"><a href="statistical-inference.html#cb183-7"></a><span class="co">## simulation</span></span>
<span id="cb183-8"><a href="statistical-inference.html#cb183-8"></a>n &lt;-<span class="st"> </span><span class="dv">1000</span></span>
<span id="cb183-9"><a href="statistical-inference.html#cb183-9"></a>x &lt;-<span class="st"> </span><span class="kw">rnorm</span>(n, <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb183-10"><a href="statistical-inference.html#cb183-10"></a><span class="kw">sum</span>(x <span class="op">&lt;</span><span class="st"> </span>z)<span class="op">/</span>n</span></code></pre></div>
<p>이제 <span class="math inline">\(p(X&lt;90)=0.024\)</span> 값의 의미를 생각해 봅니다. 이 확률은 회사측이 주장하는 <span class="math inline">\(\mu\)</span> = 100 이라는 가설을 전재로 합니다. 즉, <span class="math inline">\(p(X&lt;90|\mu=100)=0.024\)</span> 입니다. 이는 X &lt; 90 라는 사건이 굉장히 낮은 확률로 일어났다고도 볼 수 있으나 가설이 틀렸다고 보는 것이 합리적입니다. 따라서 회사측이 주장하는 사탕 평균 무게 100g의 주장을 기각하며 소비자측의 주장 <span class="math inline">\(\mu &lt; 100\)</span> 즉 사탕이 100g 보다 작다는 주장을 강하게 지지하는 결과 입니다.</p>
</div>
<div id="t-statistics" class="section level2">
<h2><span class="header-section-number">8.4</span> t-statistics</h2>
<p>위와 같은 z-score를 계산하기 위해서는 모표준편차가 필요하지만 모분산은 일반적으로 알려져있지 않기 때문에 z-score를 사용한 검정의 활용은 한정적 입니다. 모표준편차 대신 표본의 표준편차를 사용하는 통계량이 t-statistic 입니다. t 통계량은 t분포를 가지며 t분포는 <span class="math inline">\(n\)</span> 이 무한에 가까워지면 표준정규분포와 같아집니다. 표본의 표준편차가 모표준편차보다 작은 경우 t 통계량 값이 z 값보다 커지게 되어 분포 양측 tail쪽 값이 많아지고 더 두꺼운 tail 분포 모양을 가지게 됩니다.</p>
<p><span class="math display">\[ 
t = \frac{\bar{x} - \mu}{(s/\sqrt{n})}
\]</span></p>
<p>시뮬레이션을 통해 분포를 그려보겠습니다. <span class="math inline">\(N(0,1)\)</span> 분포에서 랜덤하게 <span class="math inline">\(n\)</span>={4, 10, 20, 50, 100, 1000} 개의 표본을 뽑는 과정을 1000회 반복한 후 boxplot을 그려보겠습니다.</p>
<div class="sourceCode" id="cb184"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb184-1"><a href="statistical-inference.html#cb184-1"></a>tstat &lt;-<span class="st"> </span><span class="cf">function</span>(x, mu){</span>
<span id="cb184-2"><a href="statistical-inference.html#cb184-2"></a>  (<span class="kw">mean</span>(x)<span class="op">-</span>mu)<span class="op">/</span>(<span class="kw">sd</span>(x)<span class="op">/</span><span class="kw">sqrt</span>(<span class="kw">length</span>(x)))</span>
<span id="cb184-3"><a href="statistical-inference.html#cb184-3"></a>}</span>
<span id="cb184-4"><a href="statistical-inference.html#cb184-4"></a></span>
<span id="cb184-5"><a href="statistical-inference.html#cb184-5"></a>mu &lt;-<span class="st"> </span><span class="dv">0</span></span>
<span id="cb184-6"><a href="statistical-inference.html#cb184-6"></a>sigma &lt;-<span class="st"> </span><span class="dv">1</span></span>
<span id="cb184-7"><a href="statistical-inference.html#cb184-7"></a>M &lt;-<span class="st"> </span><span class="dv">1000</span></span>
<span id="cb184-8"><a href="statistical-inference.html#cb184-8"></a>n &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">4</span>, <span class="dv">10</span>, <span class="dv">20</span>, <span class="dv">50</span>, <span class="dv">100</span>, <span class="dv">1000</span>)</span>
<span id="cb184-9"><a href="statistical-inference.html#cb184-9"></a></span>
<span id="cb184-10"><a href="statistical-inference.html#cb184-10"></a>tstat_array &lt;-<span class="st"> </span><span class="kw">replicate</span>(M, </span>
<span id="cb184-11"><a href="statistical-inference.html#cb184-11"></a>                         <span class="kw">sapply</span>(n, <span class="cf">function</span>(x){</span>
<span id="cb184-12"><a href="statistical-inference.html#cb184-12"></a>                           <span class="kw">tstat</span>(<span class="kw">rnorm</span>(x, mu, sigma), mu)</span>
<span id="cb184-13"><a href="statistical-inference.html#cb184-13"></a>                           }))</span>
<span id="cb184-14"><a href="statistical-inference.html#cb184-14"></a><span class="kw">dim</span>(tstat_array)</span>
<span id="cb184-15"><a href="statistical-inference.html#cb184-15"></a></span>
<span id="cb184-16"><a href="statistical-inference.html#cb184-16"></a><span class="co">## transposition</span></span>
<span id="cb184-17"><a href="statistical-inference.html#cb184-17"></a>tstat_array &lt;-<span class="st"> </span><span class="kw">t</span>(tstat_array)</span>
<span id="cb184-18"><a href="statistical-inference.html#cb184-18"></a><span class="kw">dim</span>(tstat_array)</span>
<span id="cb184-19"><a href="statistical-inference.html#cb184-19"></a><span class="kw">colnames</span>(tstat_array) &lt;-<span class="st"> </span><span class="kw">as.character</span>(n)</span>
<span id="cb184-20"><a href="statistical-inference.html#cb184-20"></a><span class="kw">boxplot</span>(tstat_array)</span>
<span id="cb184-21"><a href="statistical-inference.html#cb184-21"></a></span>
<span id="cb184-22"><a href="statistical-inference.html#cb184-22"></a>tstat_df_long &lt;-<span class="st"> </span><span class="kw">as.data.frame</span>(tstat_array) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb184-23"><a href="statistical-inference.html#cb184-23"></a><span class="st">  </span><span class="kw">pivot_longer</span>(<span class="dt">cols=</span><span class="kw">everything</span>())</span>
<span id="cb184-24"><a href="statistical-inference.html#cb184-24"></a><span class="kw">ggplot</span>(tstat_df_long, <span class="kw">aes</span>(<span class="dt">x=</span>name, <span class="dt">y=</span>value)) <span class="op">+</span></span>
<span id="cb184-25"><a href="statistical-inference.html#cb184-25"></a><span class="st">  </span><span class="kw">geom_boxplot</span>()</span>
<span id="cb184-26"><a href="statistical-inference.html#cb184-26"></a></span>
<span id="cb184-27"><a href="statistical-inference.html#cb184-27"></a>tstat_df_long &lt;-<span class="st"> </span><span class="kw">as.data.frame</span>(tstat_array) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb184-28"><a href="statistical-inference.html#cb184-28"></a><span class="st">  </span><span class="kw">pivot_longer</span>(<span class="dt">cols=</span><span class="kw">everything</span>()) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb184-29"><a href="statistical-inference.html#cb184-29"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">name=</span><span class="kw">fct_relevel</span>(name, <span class="st">&quot;4&quot;</span>, <span class="st">&quot;10&quot;</span>, <span class="st">&quot;20&quot;</span>, <span class="st">&quot;50&quot;</span>, <span class="st">&quot;100&quot;</span>, <span class="st">&quot;1000&quot;</span>))</span>
<span id="cb184-30"><a href="statistical-inference.html#cb184-30"></a><span class="kw">ggplot</span>(tstat_df_long, <span class="kw">aes</span>(<span class="dt">x=</span>name, <span class="dt">y=</span>value)) <span class="op">+</span></span>
<span id="cb184-31"><a href="statistical-inference.html#cb184-31"></a><span class="st">  </span><span class="kw">geom_boxplot</span>()</span></code></pre></div>
</div>
<div id="two-sample-significance-tests" class="section level2">
<h2><span class="header-section-number">8.5</span> Two sample significance tests</h2>
<p>두 그룹의 데이터 (표본)을 가지고 있을 때 두 그룹이 통계적으로 차이가 있는지를 검증하는 방법으로 (코흐트 데이터, Case-control 데이터) 시뮬레이션에 의한 방법을 먼저 소개하고 다음 장에서 확률 분포를 이용한 통계적 검증을 알아보겠습니다.</p>
<p>카페인(커피)이 초초한 상태를 유발하는가? 라는 질문에 답하기 위해서 다음 데이터를 얻었습니다. 다음 값들은 커피를 제공한 그룹과 그렇지 않은 그룹의 손가락 탭핑 횟수를 비디오로 분석한 데이터 입니다. 이럴 경우 일반적으로 두 그룹의 평균의 차이를 비교합니다.</p>
<div class="sourceCode" id="cb185"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb185-1"><a href="statistical-inference.html#cb185-1"></a>coff &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">245</span>, <span class="dv">246</span>, <span class="dv">246</span>, <span class="dv">248</span>, <span class="dv">248</span>, <span class="dv">248</span>, <span class="dv">250</span>, <span class="dv">250</span>, <span class="dv">250</span>, <span class="dv">252</span>)</span>
<span id="cb185-2"><a href="statistical-inference.html#cb185-2"></a>nocoff &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">242</span>, <span class="dv">242</span>, <span class="dv">242</span>, <span class="dv">244</span>, <span class="dv">244</span>, <span class="dv">245</span>, <span class="dv">246</span>, <span class="dv">247</span>, <span class="dv">248</span>, <span class="dv">248</span>)</span>
<span id="cb185-3"><a href="statistical-inference.html#cb185-3"></a>obsdiff &lt;-<span class="st"> </span><span class="kw">mean</span>(coff) <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(nocoff)</span>
<span id="cb185-4"><a href="statistical-inference.html#cb185-4"></a>obsdiff</span></code></pre></div>
<p>차이는 3.5가 나왔지만 이 차이가 얼마나 통계적으로 유의한지를 알아야 합니다. 시뮬레이션에 의한 방법은 위 두 그룹의 데이터들을 랜덤으로 섞은 후 다시 두 그룹으로 나누어 차이를 계산하고 이 과정을 반복해서 분포를 그린 후 유의성을 계산하는 과정입니다.</p>
<p><strong>[EXERCISE]</strong> 두 그룹 데이터에서 임으로 10명을 두 번 뽑아 그 평균의 차이를 계산하시오</p>
<div class="sourceCode" id="cb186"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb186-1"><a href="statistical-inference.html#cb186-1"></a>caf &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">245</span>, <span class="dv">246</span>, <span class="dv">246</span>, <span class="dv">248</span>, <span class="dv">248</span>, <span class="dv">248</span>, <span class="dv">250</span>, <span class="dv">250</span>, <span class="dv">250</span>, <span class="dv">252</span>)</span>
<span id="cb186-2"><a href="statistical-inference.html#cb186-2"></a>no_caf &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">242</span>, <span class="dv">242</span>, <span class="dv">242</span>, <span class="dv">244</span>, <span class="dv">244</span>, <span class="dv">245</span>, <span class="dv">246</span>, <span class="dv">247</span>, <span class="dv">248</span>, <span class="dv">248</span>)</span>
<span id="cb186-3"><a href="statistical-inference.html#cb186-3"></a>dat &lt;-<span class="st"> </span><span class="kw">c</span>(caf, no_caf) </span>
<span id="cb186-4"><a href="statistical-inference.html#cb186-4"></a>obs &lt;-<span class="st"> </span><span class="kw">mean</span>(caf) <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(no_caf)</span>
<span id="cb186-5"><a href="statistical-inference.html#cb186-5"></a></span>
<span id="cb186-6"><a href="statistical-inference.html#cb186-6"></a>x &lt;-<span class="st"> </span><span class="kw">sample</span>(dat, <span class="dv">10</span>, <span class="dt">replace=</span>T)</span>
<span id="cb186-7"><a href="statistical-inference.html#cb186-7"></a>y &lt;-<span class="st"> </span><span class="kw">sample</span>(dat, <span class="dv">10</span>, <span class="dt">replace=</span>T)</span>
<span id="cb186-8"><a href="statistical-inference.html#cb186-8"></a></span>
<span id="cb186-9"><a href="statistical-inference.html#cb186-9"></a><span class="kw">mean</span>(x) <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(y)</span></code></pre></div>
<p><strong>[EXERCISE]</strong> 위 예제의 과정을 1000번 반복하고 계산된 차이값들로 분포를 그리시오(for 문 이용)</p>
<div class="sourceCode" id="cb187"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb187-1"><a href="statistical-inference.html#cb187-1"></a>diff_vals &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="dv">0</span>, <span class="dv">1000</span>)</span>
<span id="cb187-2"><a href="statistical-inference.html#cb187-2"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">1000</span>){</span>
<span id="cb187-3"><a href="statistical-inference.html#cb187-3"></a>  x &lt;-<span class="st"> </span><span class="kw">sample</span>(dat, <span class="dv">10</span>, <span class="dt">replace=</span>T)</span>
<span id="cb187-4"><a href="statistical-inference.html#cb187-4"></a>  y &lt;-<span class="st"> </span><span class="kw">sample</span>(dat, <span class="dv">10</span>, <span class="dt">replace=</span>T)</span>
<span id="cb187-5"><a href="statistical-inference.html#cb187-5"></a>  diff_vals[i] &lt;-<span class="st"> </span><span class="kw">mean</span>(x) <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(y)</span>
<span id="cb187-6"><a href="statistical-inference.html#cb187-6"></a>}</span>
<span id="cb187-7"><a href="statistical-inference.html#cb187-7"></a></span>
<span id="cb187-8"><a href="statistical-inference.html#cb187-8"></a><span class="kw">ggplot</span>(<span class="kw">data.frame</span>(diff_vals), <span class="kw">aes</span>(<span class="dt">x=</span>diff_vals)) <span class="op">+</span></span>
<span id="cb187-9"><a href="statistical-inference.html#cb187-9"></a><span class="st">  </span><span class="kw">geom_histogram</span>()</span></code></pre></div>
<p><strong>[EXERCISE]</strong> 분포에서 실제 관측한 3.5 값의 위치를 표시하고 관측값보다 더 극단적인 경우가 나올 경우의 비율을 계산하시오 (위 예제 코드의 연속)</p>
<div class="sourceCode" id="cb188"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb188-1"><a href="statistical-inference.html#cb188-1"></a>emp_pval &lt;-<span class="st"> </span><span class="kw">sum</span>(diff_vals <span class="op">&gt;</span><span class="st"> </span>obs)<span class="op">/</span><span class="kw">length</span>(diff_vals)</span>
<span id="cb188-2"><a href="statistical-inference.html#cb188-2"></a></span>
<span id="cb188-3"><a href="statistical-inference.html#cb188-3"></a>textstring &lt;-<span class="st"> </span><span class="kw">paste</span>(<span class="st">&quot;p(X &gt; &quot;</span>, obs, <span class="st">&quot;) = &quot;</span>, emp_pval, <span class="dt">sep=</span><span class="st">&quot;&quot;</span>)</span>
<span id="cb188-4"><a href="statistical-inference.html#cb188-4"></a><span class="kw">ggplot</span>(<span class="kw">data.frame</span>(diff_vals), <span class="kw">aes</span>(<span class="dt">x=</span>diff_vals)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb188-5"><a href="statistical-inference.html#cb188-5"></a><span class="st">  </span><span class="kw">geom_histogram</span>() <span class="op">+</span></span>
<span id="cb188-6"><a href="statistical-inference.html#cb188-6"></a><span class="st">  </span><span class="kw">geom_segment</span>(<span class="kw">aes</span>(<span class="dt">x =</span> obs, </span>
<span id="cb188-7"><a href="statistical-inference.html#cb188-7"></a>                   <span class="dt">y =</span> <span class="dv">30</span>, </span>
<span id="cb188-8"><a href="statistical-inference.html#cb188-8"></a>                   <span class="dt">xend =</span> obs, </span>
<span id="cb188-9"><a href="statistical-inference.html#cb188-9"></a>                   <span class="dt">yend =</span> <span class="dv">5</span>), </span>
<span id="cb188-10"><a href="statistical-inference.html#cb188-10"></a>               <span class="dt">arrow =</span> <span class="kw">arrow</span>(), </span>
<span id="cb188-11"><a href="statistical-inference.html#cb188-11"></a>               <span class="dt">size=</span><span class="dv">2</span>) <span class="op">+</span></span>
<span id="cb188-12"><a href="statistical-inference.html#cb188-12"></a><span class="st">  </span><span class="kw">annotate</span>(<span class="st">&quot;text&quot;</span>, </span>
<span id="cb188-13"><a href="statistical-inference.html#cb188-13"></a>           <span class="dt">label =</span> obs, </span>
<span id="cb188-14"><a href="statistical-inference.html#cb188-14"></a>           <span class="dt">x =</span> obs, </span>
<span id="cb188-15"><a href="statistical-inference.html#cb188-15"></a>           <span class="dt">y =</span> <span class="dv">35</span>, </span>
<span id="cb188-16"><a href="statistical-inference.html#cb188-16"></a>           <span class="dt">size =</span> <span class="dv">5</span>) <span class="op">+</span></span>
<span id="cb188-17"><a href="statistical-inference.html#cb188-17"></a><span class="st">  </span><span class="kw">annotate</span>(<span class="st">&quot;text&quot;</span>, </span>
<span id="cb188-18"><a href="statistical-inference.html#cb188-18"></a>           <span class="dt">label =</span> textstring, </span>
<span id="cb188-19"><a href="statistical-inference.html#cb188-19"></a>           <span class="dt">x =</span> <span class="fl">2.5</span>, </span>
<span id="cb188-20"><a href="statistical-inference.html#cb188-20"></a>           <span class="dt">y =</span> <span class="dv">100</span>, </span>
<span id="cb188-21"><a href="statistical-inference.html#cb188-21"></a>           <span class="dt">size =</span> <span class="dv">5</span>) <span class="op">+</span></span>
<span id="cb188-22"><a href="statistical-inference.html#cb188-22"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x=</span><span class="st">&quot;X&quot;</span>, <span class="dt">y=</span><span class="st">&quot;Count&quot;</span>)</span></code></pre></div>
<p>관측된 차이 3.5는 가능한 차이값들을 모두 그려본 분포에서 가장자리에 위치합니다. 관측값이 중심에 가까울수록 흔하게 관측되는 것으로 두 그룹간 차이가 랜덤하게 나누어도 높은 확률로 관측 가능한 값이라는 의미입니다. 반면 가장자리에 위치할수록 그룹간의 차이가 랜덤이 아닌 특정 요인이 작용해서 발생한 사건으로 해석할 수 있습니다.</p>
<p><span class="math inline">\(p(X&gt;3.5)\)</span>는 위 사건이 발생한 경우(3.5)보다 극단적으로 큰 값의 사건이 발생할 확률을 말하며 이는 <span class="math inline">\(1-p(X \le 3.5)\)</span> 이며 <span class="math inline">\(p(X \le 3.5)\)</span>는 누적분포함수, <code>qnorm</code>으로 구할 수 있습니다. 예제에서는 이 값이 0.003으로 관측값 3.5는 랜덤으로는 거의 일어나기 힘든 확률의 사건임을 알 수 있습니다.</p>
<p>통계적 유의성 검정의 측면에서 생각해 보면 위 두 그룹의 데이터를 랜덤하게 섞은 후 그룹을 다시 나누는 것은 그룹간 차이가 없다는 것을 가정하는 것 입니다. 즉, <span class="math inline">\(\mu_1 = \mu_2\)</span> 이며 이 상태에서 <span class="math inline">\(X=\mu_1 - \mu_2\)</span> 인 확률변수라 할 때 <span class="math inline">\(p(X &gt; 3.5)\)</span>, 즉, <span class="math inline">\(p(\mu_1 - \mu_2 &gt; 3.5 | \mu_1 = \mu_2)\)</span>를 계산 한 값입니다. 이 값이 0.001 이라는 것은 희박한 확률로 3.5가 관측되었다고 볼 수 있으나 가정이 틀렸다고 보는 것이 더욱 합리적 입니다. 따라서 <span class="math inline">\(\mu_1 = \mu_2\)</span>를 받아들이지 않고 (기각하고) <span class="math inline">\(\mu_1 \ne \mu_2\)</span>를 지지하는 확률이 높아지게 되는 것 입니다.</p>
</div>
<div id="estimation-and-confidence-interval" class="section level2">
<h2><span class="header-section-number">8.6</span> Estimation and confidence interval</h2>
<p>앞서 예제에서 두 그룹간 평균의 차이를 통계량 (statistic) 으로 볼 수 있습니다. 통계량은 표본의 특징을 모사하는 값으로 앞서 배운 대푯값들도 통계량으로 볼 수 있고 이들은 모수 (parameter)를 추정하기 위한 값입니다. 이 값이 얼마나 모수와 가까운지, 즉 차이가 0에 가까운지 판단하는 것은 통계적 추정에서 가장 중요한 부분 중 하나 입니다. 일반적으로 <span class="math inline">\(\mu, \sigma\)</span> 등 모수는 <span class="math inline">\(\theta\)</span>로 표현하고 <span class="math inline">\(\theta\)</span>를 추정하기위한 통계량은 <span class="math inline">\(\hat{\theta}\)</span>로 표현합니다. 다음 식으로 우리가 계산한 통계량이 얼마나 모수에 가까운지는 다음 식으로 알 수 있습니다.</p>
<p><span class="math display">\[
E((\hat{\theta} - \theta)^2) = VAR(\hat{\theta}) + (E(\hat{\theta}-\theta))^2 = \text{variance} + \text{bias}^2
\]</span>
우리가 언급하는 통계량들은 대부분 unbiased 입니다. 불편추정량 (unbiased estimator)이라 부르며 다음과 같은 것들이 있습니다.</p>
<ul>
<li><span class="math inline">\(E(\bar{x}) = \mu\)</span></li>
<li><span class="math inline">\(E(\bar{p}) = p\)</span></li>
<li><span class="math inline">\(E(s^2) = \sigma^2\)</span></li>
</ul>
<p>예를 들어 A poll asking a random sample of 1003 whether marriages between same-sex couples should be recognized by law as valid. 55% said yes, 이 경우 A randomly selected person would responding yes with <span class="math inline">\(\hat{p}\)</span> = 0.55 입니다.</p>
<p>여기서 이러한 투표를 100번 반복 했을 때 계산되는 찬성 비율 값들이 대부분 (또는 95%는) 어디에 모여 있는가? 라는 질문을 할 수 있고 이는 모집단에서의 찬성 비율 (모수, 진짜) 값의 95% 신뢰구간은 무엇인가? 라는 질문과 같습니다.</p>
<p>개념 설명을 위해 다음 t 통계량 시뮬레이션을 수행해 보겠습니다.</p>
<div class="sourceCode" id="cb189"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb189-1"><a href="statistical-inference.html#cb189-1"></a>tstat &lt;-<span class="st"> </span><span class="cf">function</span>(x, mu){</span>
<span id="cb189-2"><a href="statistical-inference.html#cb189-2"></a>  SE &lt;-<span class="st"> </span><span class="kw">sd</span>(x)<span class="op">/</span><span class="kw">sqrt</span>(<span class="kw">length</span>(x))</span>
<span id="cb189-3"><a href="statistical-inference.html#cb189-3"></a>  (<span class="kw">mean</span>(x)<span class="op">-</span>mu)<span class="op">/</span>SE</span>
<span id="cb189-4"><a href="statistical-inference.html#cb189-4"></a>}</span>
<span id="cb189-5"><a href="statistical-inference.html#cb189-5"></a></span>
<span id="cb189-6"><a href="statistical-inference.html#cb189-6"></a>mu &lt;-<span class="st"> </span><span class="dv">0</span></span>
<span id="cb189-7"><a href="statistical-inference.html#cb189-7"></a>sigma &lt;-<span class="st"> </span><span class="dv">1</span></span>
<span id="cb189-8"><a href="statistical-inference.html#cb189-8"></a>M &lt;-<span class="st"> </span><span class="dv">1000</span></span>
<span id="cb189-9"><a href="statistical-inference.html#cb189-9"></a>n &lt;-<span class="st"> </span><span class="dv">4</span> </span>
<span id="cb189-10"><a href="statistical-inference.html#cb189-10"></a></span>
<span id="cb189-11"><a href="statistical-inference.html#cb189-11"></a>tstats &lt;-<span class="st"> </span><span class="kw">replicate</span>(M, <span class="kw">tstat</span>(<span class="kw">rnorm</span>(x, mu, sigma), mu))</span>
<span id="cb189-12"><a href="statistical-inference.html#cb189-12"></a><span class="kw">ggplot</span>(<span class="kw">data.frame</span>(<span class="dt">x=</span>tstats), <span class="kw">aes</span>(<span class="dt">x=</span>x)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb189-13"><a href="statistical-inference.html#cb189-13"></a><span class="st">  </span><span class="kw">geom_histogram</span>()</span>
<span id="cb189-14"><a href="statistical-inference.html#cb189-14"></a></span>
<span id="cb189-15"><a href="statistical-inference.html#cb189-15"></a><span class="kw">quantile</span>(tstats, <span class="kw">c</span>(<span class="fl">0.025</span>, <span class="fl">0.975</span>))</span></code></pre></div>
<p>앞 뒤 0.025%를 제외한 구간은 위와 같으며 이는 아래와 같이 표현됩니다.
<span class="math display">\[
-1.97 &lt; \frac{\bar{x}-\mu}{SE} &lt; 2.033
\]</span>
이를 다시 정리하면 다음과 같습니다.</p>
<p><span class="math display">\[
\bar{x} - 2.033 \cdot SE  &lt; \mu &lt; \bar{x}+1.97\cdot SE
\]</span>
즉, 위 구간이 1000번 반복해서 표본평균을 구할 경우 위 구간이 95% 데이터들이 모여있는 구간이 되며 모평균 <span class="math inline">\(\mu\)</span>의 95% 신뢰구간이라고 합니다. 보통 신뢰구간의 해석은 다음과 같습니다.</p>
<p><img src="images/08/07.PNG" /></p>
</div>
<div id="bootstrap" class="section level2">
<h2><span class="header-section-number">8.7</span> Bootstrap</h2>
<p>특정 확률변수의 분포를 모를 경우 분포를 생성하는 시뮬레이션 방법으로 적당한 수의 샘플이 있을 경우에 가능한 방법입니다. <code>UsingR</code> 패키지의 <code>Medicare</code> 데이터셋을 예로 들면, 병원비 청구 금액과 지불금액의 차이가 큰 범위의 분포를 가지고 있는 상황이며 이 데이터의 모평균에 대한 신뢰구간을 구하는 문제입니다.</p>
<div class="sourceCode" id="cb190"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb190-1"><a href="statistical-inference.html#cb190-1"></a><span class="kw">library</span>(UsingR)</span>
<span id="cb190-2"><a href="statistical-inference.html#cb190-2"></a><span class="kw">str</span>(Medicare)</span>
<span id="cb190-3"><a href="statistical-inference.html#cb190-3"></a>gapdata &lt;-<span class="st"> </span>Medicare <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb190-4"><a href="statistical-inference.html#cb190-4"></a><span class="st">  </span><span class="kw">filter</span>(DRG.Definition<span class="op">==</span><span class="st">&quot;638 - DIABETES W CC&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb190-5"><a href="statistical-inference.html#cb190-5"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">gap=</span>Average.Covered.Charges<span class="op">-</span>Average.Total.Payments) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb190-6"><a href="statistical-inference.html#cb190-6"></a><span class="st">  </span>dplyr<span class="op">::</span><span class="kw">select</span>(Provider.Id, gap)</span>
<span id="cb190-7"><a href="statistical-inference.html#cb190-7"></a>gapdata</span>
<span id="cb190-8"><a href="statistical-inference.html#cb190-8"></a><span class="kw">str</span>(gapdata)</span>
<span id="cb190-9"><a href="statistical-inference.html#cb190-9"></a><span class="kw">ggplot</span>(gapdata, <span class="kw">aes</span>(<span class="dt">x=</span>gap)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_histogram</span>(<span class="dt">bins=</span><span class="dv">30</span>)</span></code></pre></div>
<p>단순히 생각하면 위 데이터의 평균값 <code>mean(gapdata$gap)</code>을 계산하여 모평균을 유추할 수도 있습니다. 그러나 그렇게 분석할 경우 추정된 값이 얼마나 통계적으로 유의한지 알 수 없게 됩니다. 따라서 아래와 같이 boostrap 방법을 사용하여 분포를 생성할 수 있고 이를 이용하여 신뢰구간을 구하고 모평균에 대한 해석을 수행할 수 있습니다.</p>
<div class="sourceCode" id="cb191"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb191-1"><a href="statistical-inference.html#cb191-1"></a>M &lt;-<span class="st"> </span><span class="dv">2000</span></span>
<span id="cb191-2"><a href="statistical-inference.html#cb191-2"></a>xbar &lt;-<span class="st"> </span><span class="kw">mean</span>(gapdata<span class="op">$</span>gap)</span>
<span id="cb191-3"><a href="statistical-inference.html#cb191-3"></a>res &lt;-<span class="st"> </span><span class="kw">replicate</span>(M, {</span>
<span id="cb191-4"><a href="statistical-inference.html#cb191-4"></a>  xstar &lt;-<span class="st"> </span><span class="kw">sample</span>(gapdata<span class="op">$</span>gap, <span class="kw">length</span>(gapdata<span class="op">$</span>gap), <span class="dt">replace=</span>T)</span>
<span id="cb191-5"><a href="statistical-inference.html#cb191-5"></a>  <span class="kw">mean</span>(xstar) <span class="op">-</span><span class="st"> </span>xbar</span>
<span id="cb191-6"><a href="statistical-inference.html#cb191-6"></a>})</span>
<span id="cb191-7"><a href="statistical-inference.html#cb191-7"></a>conf95 &lt;-<span class="st"> </span><span class="kw">quantile</span>(res, <span class="kw">c</span>(<span class="fl">0.025</span>, <span class="fl">0.975</span>))</span>
<span id="cb191-8"><a href="statistical-inference.html#cb191-8"></a><span class="kw">ggplot</span>(<span class="kw">data.frame</span>(res), <span class="kw">aes</span>(<span class="dt">x=</span>res)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb191-9"><a href="statistical-inference.html#cb191-9"></a><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">bins=</span><span class="dv">30</span>) <span class="op">+</span></span>
<span id="cb191-10"><a href="statistical-inference.html#cb191-10"></a><span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">xintercept=</span>conf95, <span class="dt">linetype=</span><span class="st">&quot;dashed&quot;</span>, <span class="dt">color=</span><span class="st">&#39;blue&#39;</span>, <span class="dt">size=</span><span class="fl">1.2</span>) <span class="op">+</span></span>
<span id="cb191-11"><a href="statistical-inference.html#cb191-11"></a><span class="st">  </span><span class="kw">geom_label</span>(<span class="kw">aes</span>(<span class="dt">x=</span>conf95[<span class="dv">1</span>], <span class="dt">y=</span><span class="dv">400</span>, <span class="dt">label=</span><span class="kw">round</span>(conf95[<span class="dv">1</span>]))) <span class="op">+</span></span>
<span id="cb191-12"><a href="statistical-inference.html#cb191-12"></a><span class="st">  </span><span class="kw">geom_label</span>(<span class="kw">aes</span>(<span class="dt">x=</span>conf95[<span class="dv">2</span>], <span class="dt">y=</span><span class="dv">400</span>, <span class="dt">label=</span><span class="kw">round</span>(conf95[<span class="dv">2</span>])))</span>
<span id="cb191-13"><a href="statistical-inference.html#cb191-13"></a></span>
<span id="cb191-14"><a href="statistical-inference.html#cb191-14"></a></span>
<span id="cb191-15"><a href="statistical-inference.html#cb191-15"></a>xbar <span class="op">+</span><span class="st"> </span>conf95</span></code></pre></div>
<p>따라서 해석은 병원비 청구금액과 지불금액의 차이에 대한 모평균의 95% 신뢰구간은 (13097.79, 18068.15)이며 이는 반복해서 100번의 신뢰구간을 구했을 때 95개의 신뢰구간이 모평균을 포함할 수 있는 구간이다 라고 해석할 수 있습니다.</p>
</div>
<div id="problem-08" class="section level2">
<h2><span class="header-section-number">8.8</span> Problem 08</h2>
<p><code>datasets</code> 패키지의 <code>co2</code> 데이터셋은 1959년부터 1997년 사이 측정된 공기중 이산화탄소의 농도이다. 연구자들은 1997년이 1959년보다 더 많은 CO2가 방출되고 있다고 주장하고 있다. 이들의 주장을 통계적으로 검증하기 위해서 데이터를 두 그룹으로 나누고 두 그룹간의 차이가 유의한지 시뮬레이션에 의한 방법으로 알아보고자 한다. 통계적 검증은 1997년과 1959년 CO2 방출량이 같다라는 가정을 하고 평균의 차이값에 대한 분포에서의 확률을 구한 후 확률이 낮으면 같다라는 가정이 틀린 것으로 확률이 높으면 가정이 맞는 것으로 한다.</p>
<ol style="list-style-type: decimal">
<li>1959년 데이터들을 co2a 변수에 저장하고 1997년 데이터들을 co2b 변수에 저장하시오</li>
</ol>
<div class="sourceCode" id="cb192"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb192-1"><a href="statistical-inference.html#cb192-1"></a>co2a &lt;-<span class="st"> </span>co2[<span class="dv">1</span><span class="op">:</span><span class="dv">12</span>]</span>
<span id="cb192-2"><a href="statistical-inference.html#cb192-2"></a>co2b &lt;-<span class="st"> </span>co2[<span class="dv">457</span><span class="op">:</span><span class="dv">468</span>]</span></code></pre></div>
<ol start="2" style="list-style-type: decimal">
<li><p>두 그룹간 평균의 차이값을 obsdiff 변수에 저장하시오 (co2a - co2b)</p></li>
<li><p>두 그룹을 하나의 데이터셋으로 만들고 이 데이터셋에서 임의로 12개씩 샘플을 두 번 뽑아 평균의 차이를 계산하시오 (복원추출)</p></li>
<li><p>위 3)을 1000번 반복하고 각 계산된 값을 diff_vals 라는 변수에 저장하고 ggplot을 이용해서 히스토그램을 그리시오</p></li>
<li><p>diff_vals 값들 중 obsdiff 보다 큰 값들의 비율 emp_pval을 구하시오</p></li>
<li><p>emp_pval 값의 의미를 해석하고 문제에서 설정한 가정의 맞고 틀림에 대한 결론을 내리시오</p></li>
</ol>
<p><a rel="license" href="http://creativecommons.org/licenses/by-nc-nd/4.0/"><img alt="크리에이티브 커먼즈 라이선스" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-nd/4.0/88x31.png" /></a><br />이 저작물은 <a rel="license" href="http://creativecommons.org/licenses/by-nc-nd/4.0/">크리에이티브 커먼즈 저작자표시-비영리-변경금지 4.0 국제 라이선스</a>에 따라 이용할 수 있습니다.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="populations.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="confidence-intervals.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
