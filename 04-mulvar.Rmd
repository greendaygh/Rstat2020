
# Multivariate data

## Introduction

앞서 장에서는 기본적인 변수에 대한 대표값들과 두 개 이상의 변수가 주어졌을 경우 그 관계를 정량화 하는 과정을 학습했습니다. 그러나 일반적인 데이터 분석은 두 개 이상의 변수와 샘플들에 대해서 정제, 변환, 가시화, 대표값 비교 및 모델링으로 이어지는 단계로 이루어질 수 있습니다. 본 장에서는 R을 사용해서 위 데이터 분석 과정을 수행하기 위해 필요한 프로그래밍 기술을 습득하기 위해 최근 대표적으로 사용되는 apply 함수들과 dplyr 패키지 사용에 대한 학습을 목표로 합니다. 


## Data structures in R

### Vectors 

같은 타입의 데이터를 (Numeric, character, factor, ...) 모아 놓은 컨테이너로서 인덱스는 ```[```, ```]```를 사용합니다. 


```{r, eval=F}
x <- c(10.4, 5.6, 3.1, 6.4, 21.7) 
class(x)
is.numeric(x)
y <- c("X1", "Y2",  "X3",  "Y4")
class(y)
is.numeric(y)
z <- c(T, F, F, T)
class(z)
is.logical(z)
```


### Lists 

`list` 변수 타입은 `vector` 형태의 여러개의 element를 가질 수 있으며 각 element의 데이터는 문자나 숫자 어떤 데이터 타입도 가능하며 각 element vector의 길이가 모두 달라도 됩니다. list의 인덱싱에서 `[` `]`는 리스트를 반환하고 `[[` `]]`는 vector element들을 반환합니다. 


```{r, eval=F}
## list
parent_names <- c("Fred", "Mary")
number_of_children <- 2
child_ages <- c(4, 7, 9)
data.frame(parent_names, number_of_children, child_ages)
lst <- list(parent_names, number_of_children, child_ages)
lst[1]
lst[[1]]
class(lst[1])
class(lst[[1]])
lst[[1]][1]
lst[[1]][c(1,2)]
```


### Matrices

메트릭스는 같은 타입의 데이터로 채워진 사각형 모양을 갖는 컨테이너로 볼 수 있습니다. 인덱스는 ```[i, j]``` 형태로 ```i```는 row, ```j```는 column 을 가리킵니다. 메트릭스의 생성은 ```matrix``` 명령어를 사용하며 다음과 같이 각 column 별로 값을 채워 나가는 것이 기본 설정이며 ```byrow=T``` 를 통해 row를 다 채우고 그 다음 row를 채워 나가게 할 수도 있습니다. 


```{r eval=F}
mymat <- matrix(0, nrow=100, ncol=3) # 1
mymat[,1] <- 1:100 # 2
mymat[,2] <- seq(1,200,2) # 3
mymat[,3] <- seq(2,200,2) # 4

m <- matrix(c(1,2,3,4), nrow=2)
m
m <- matrix(c(1,2,3,4), nrow=2, byrow = T)
m

```

row와 column 이름은 ```rownames```와 ```colnames```로 설정이 가능하며 ```rbind```와 ```cbind```는 벡터를 연결하고 붙이는 역할을 할 수 있으나 데이터가 많거나 반복해서 수행할 경우 컴퓨터의 리소스를 많이 사용하는 문제로 느려질 수 있습니다. 

```{r, eval=F}
m <- cbind(1:3, c(1.1, 1.2, 1.3), c(1, 1, 2)) # a 3 by 3 matrix
colnames(m) <- c("x", "y", "z") # or cbind(x=..., ...)
m
dim(m)
```

### data.frame

data frame은 변수들의 집합으로 ```list```형과 비슷하지만 각 변수 element들이 똑같은 길이를 가지고 matrix 형태로 표현되는 것이 다릅니다. 즉, 각 row는 샘플을 나타내고 각 column은 변수를 나타내며 각 변수들이 갖는 샘플의 개수 (row의 길이, vector 의 길이)는 같아야 합니다. 컬럼 한 줄이 하나의 변수 이므로 새로운 변수도 컬럼 형태로 붙여 넣을 수 있습니다. 변수들의 이름을 이용하여 ```$``` 기호로 각 변수들의 데이터에 접근 할 수 있고 matrix와 같이 ```[i,j]``` 형태의 인덱싱도 가능합니다. R 기반의 데이터 분석에서는 가장 선호되는 데이터 타입이라고 볼 수 있습니다.


```{r, eval=F}
ids <- 1:10
ids
idnames <- paste("Name", ids, sep="")
idnames
students <- data.frame(ids, idnames)
students
class(students$ids)
class(students$idnames)
students$idnames
str(students)

students <- data.frame(ids, idnames, stringsAsFactors = F)
class(students$idnames)
students$idnames
students[1,]
str(students)
```


![](images/04/06.png)


## Working with data frame basics

일반적인 데이터 분석은 데이터 클리닝, 변환, 가시화, 대표값비교, 모델링의 반복적인 수행으로 진행될 수 있습니다. 특히 R에서는 data frame 타입의 데이터로 대부분의 분석이 진행되므로 data frame 기반의 다양한 기법을 익혀야 합니다. 





```{r, eval=F}
# `state.x77` 데이터셋에서 `population`과 `Life Exp`, 그리고 `Murder` 변수만을 이용한 새로운 matrix

str(state.x77)
newstate <- state.x77[,c(1,4,5)]
class(newstate)
str(newstate)
```



```{r, eval=F}
# 새로운 변수 추가
rownames(state.x77)
head(state.x77)
state_names <- rownames(state.x77)
newstate <- data.frame(state_names, state.x77[,c(1,4,5)])
head(newstate)
str(newstate)
newstate <- data.frame(state_names, state.x77[,c(1,4,5)], stringsAsFactors = F)
str(newstate)
```



### subset and filter

R에서 데이터 저장은 `data.frame`이나 `matrix` 타입을 일반적으로 사용합니다. 이 데이터의 일부 열 또는 행의 데이터만을 가져와서 별도로 저장하거나 분석이 필요할 경우가 있습니다. 이 때 인덱싱을 사용해서 일부 데이터를 선택하고 사용할 수 있으며 `subset`과 `filter` 함수도 이러한 선별 기능을 제공합니다. `subset`은 행과 열 모두를 선별할 수 있는 함수이고 `filter`는 열 (샘플)을 선택하는 함수입니다. 다음 `airquality` 데이터는 1973년 날짜별로 뉴욕의 공기질을 측정한 데이터 입니다. `NA`를 제외한 나머지 데이터만으로 새로운 데이터셋을 만들어 봅시다. `is.na`함수를 사용하면 해당 데이터가 `NA`일 경우 `TRUE`, `NA`가 아닐 경우 `FALSE` 를 반환해 줍니다. 


```{r, eval=F}
is.na(airquality$Ozone)
ozone_complete1 <- airquality[!is.na(airquality$Ozone),]
ozone_complete2 <- filter(airquality, !is.na(airquality$Ozone))
ozone_complete3 <- subset(airquality, !is.na(Ozone))
```

위 ozone_complete1와 ozone_complete2, ozone_complete3는 같은 결과를 보입니다. 그러나 ozone_complete1, 2보다는 ozone_complete3 코드가 훨씬 직관적이고 가독성이 높습니다. 특히 `airquality$ozone` 로 `$`를 사용하여 변수에 접근한 반면 subset 함수는 `Ozone`이라는 변수 이름을 사용해서 접근함으로써 코드의 간결성과 가독성을 유지할 수 있습니다. 또한 `subset`의 `select` 옵션을 이용해서 변수를 선택할 수도 있으며 `&`(AND)와 `|`(OR) 연산자를 사용해서 조건을 두 개 이상 설정할 수 있습니다. 아래 `select` 옵션에서 `-`는 해당 변수를 제외한다는 의미 입니다. 

```{r, eval=F}
ozone_complete4 <- subset(airquality, !is.na(ozone), select=c(ozone, temp, month, day))
ozone_complete5 <- subset(airquality, !is.na(ozone) & !is.na(solar.r), select=c(-month, -day))
```



### merging and split

`merge` 함수는 두 개 이상의 데이터셋을 통합하는 기능을 수행하는 함수입니다. 특히 `rbind`나 `cbind`와는 다르게,  결합하는 두 데이터에 공통적이거나 한 쪽의 데이터를 기준으로 결합을 수행 합니다. `?merge`를 참고하면 `by`, `by.x`, `by.y`, `all`, `all.x`, `all.y` 등의 옵션으로 이러한 설정을 수행할 수 있습니다. 간단한 예제를 통해서 이해해 보겠습니다.  

10명의 사람이 있고 이 사람들의 나이와 성별을 각각 나타낸 두 데이터셋이 있습니다. 그런데 df1은 나이만을 df2는 성별 정보만을 가지고 있으며 두 정보 모두 제공된 사람은 3명 (인덱스 4,5,6) 뿐입니다. 이제 merge를 이용해서 두 데이터셋을 결합해 보겠습니다. 


```{r, eval=F}
## merge
df1 <- data.frame(id=c(1,2,3,4,5,6), age=c(30, 41, 33, 56, 20, 17))
df2 <- data.frame(id=c(4,5,6,7,8,9), gender=c("f", "f", "m", "m", "f", "m"))

df_inner <- merge(df1, df2, by="id", all=F)
df_outer <- merge(df1, df2, by="id", all=T)
df_left_outer <- merge(df1, df2, by="id", all.x=T)
df_right_outer <- merge(df1, df2, by="id", all.y=T)
```

만약 두 데이터셋의 id가 다를 경우나 각각 다른 기준으로 결합해야 하는 경우는 `by`대신 `by.x`, `by.y` 옵션을 사용할 수 있습니다. 

`split` 함수는 데이터를 특정 기준으로 나누는 역할을 하며 해당 기준은 factor 형 벡터 형태로 주어질 수 있습니다.  예를 들어 `airquality` 데이터의 `month` 변수를 기준으로 데이터를 분리해 보겠습니다. 


```{r, eval=F}
str(airquality)
g <- factor(airquality$Month)
airq_split <- split(airquality, g)
class(airq_split)
str(airq_split)
```

위와 같이 `airq_split`은 길이가 5인 (5, 6, 7, 8, 9월) `list`타입이 되었고 각 요소는 서로 다른 size의 `data.frame`형으로 구성 된 것을 확인할 수 있습니다. 


### transforming data

R에서 기존 가지고 있는 데이터의 변경은 새로운 변수의 추가, 삭제, 변형과 샘플의 추가, 삭제, 변형을 생각해 볼 수 있습니다. 이러한 기능은 앞에서 배운 `merge`, `split`이나 `rbind`, `cbind`, 그리고 인덱싱을 활용한 값 변경 등의 방법을 이용할 수 있습니다. 또한 가장 직관적으로 필요한 변수들을 기존 데이터셋에서 추출한 후 `data.frame` 명령어를 사용해서 새로운 데이터셋으로 만들어주면 될 것 입니다. 

이러한 방법들 외에 `within`을 사용할 경우 특정 변수의 변형과 이를 반영한 새로운 데이터셋을 어렵지 않게 만들수 있습니다. `with` 함수의 사용 예와 함께 `within` 함수를 사용하여 데이터를 변형하는 예를 살펴봅니다. `with`나 `within` 함수는 R을 활용하는데 많이 사용되는 함수들은 아닙니다. 또한 이러한 기능들은 `dplyr` 등의 패키지에서 제공하는 경우가 많아서 필수적으로 익힐 부분은 아닙니다. 그러나 개념적인 이해를 돕기위한 좋은 도구들이며 여전히 고수준의 R 사용자들이 코드에 사용하고 있는 함수들이므로 알아두는 것이 좋습니다. 

```{r, eval=F}
## without with
ozone_complete <- airquality[!is.na(airquality$Ozone),"Ozone"]
temp_complete <- airquality[!is.na(airquality$Temp),"Temp"]
print(mean(ozone_complete))
print(mean(temp_complete))

## with
with(airquality, {
  print(mean(Ozone[!is.na(Ozone)]))
  print(mean(Temp[!is.na(Temp)]))
})

```

위 `with` 함수에서 보는바와 같이 `$`를 이용한 변수 접근 대신 `with`함수 내에서는 (`{`, `}` 안에서) 해당 `data.frame`에 있는 변수 이름을 직접 접근할 수 있으며 따라서 코드의 간결함과 가독성이 향상됩니다. 

`within` 함수는 `with`함수와 같이 `{`, `}` 안에서 변수의 이름만으로 해당 변수에 접근이 가능하나 입력된 데이터와 변경된 변수(들)을 반환한다는 점이 다릅니다. 아래 예는 `airquality` 데이터의 화씨 (Fahrenheit) 온도를 섭씨 (Celsius) 온도로 변환해서 새로운 데이터셋을 만드는 코드입니다. `data.frame`을 이용한 코드와 비교해 보시기 바랍니다. 데이터셋 내에서 참조할 변수들이 많아질 경우 `airquality$xxx` 식의 코드를 줄이는 것 만으로도 코드의 가독성과 간결성을 유지할 수 있습니다.  


```{r, eval=F}
newairquality <- within(airquality, {
  celsius = round((5*(Temp-32))/9, 2)
})
head(newairquality)

## data.frame
celsius <- round((5*(airquality$Temp-32))/9, 2)
newairquality <- data.frame(airquality, celsius)
head(newairquality)
```






**EXERCISE** airquality 데이터의 Month에 따른 Ozone 의 분포를 boxplot을 이용해서 비교하시오. (subset??)을 이용하여 Month에 따른 각각의 Ozone의 값들로 새로운 변수들 v5, v6, v7, v8, v9을 만들고 이들을 하나의 data frame으로 만드시오 

```{r}
head(airquality)

boxplot(formula=Ozone~Month, data=airquality)
boxplot(airquality$Ozone~airquality$Month)
```

**EXERCISE** 가장 직관적으로 먼저 필요한 기능을 하나의 데이터 엘리먼트에 대해서 수행하는 스크립트를 먼저 작성해 보고 필요한 index를 붙이거나 for 문을 활용해서 원하는 형태의 데이터 변환을 완료하시오 

```{r, eval=F}
oz <- data.frame(airquality$Ozone[airquality$Month==5],
airquality$Ozone[airquality$Month==6],
airquality$Ozone[airquality$Month==7],
airquality$Ozone[airquality$Month==8],
airquality$Ozone[airquality$Month==9])

oz <- list(airquality$Ozone[airquality$Month==5],
airquality$Ozone[airquality$Month==6],
airquality$Ozone[airquality$Month==7],
airquality$Ozone[airquality$Month==8],
airquality$Ozone[airquality$Month==9])

boxplot(oz)

##
soz <- list()
soz[[1]] <- (oz[[1]]-mean(oz[[1]], na.rm=T))/sd(oz[[1]], na.rm=T)
soz[[2]] <- (oz[[2]]-mean(oz[[2]], na.rm=T))/sd(oz[[2]], na.rm=T)
soz[[3]] <- (oz[[3]]-mean(oz[[3]], na.rm=T))/sd(oz[[3]], na.rm=T)
soz[[4]] <- (oz[[4]]-mean(oz[[4]], na.rm=T))/sd(oz[[4]], na.rm=T)
soz[[5]] <- (oz[[5]]-mean(oz[[5]], na.rm=T))/sd(oz[[5]], na.rm=T)
soz

boxplot(soz)
soz <- list()
for(i in 1:5){
  soz[[i]] <- (oz[[i]]-mean(oz[[i]], na.rm=T))/sd(oz[[i]], na.rm=T)
}
boxplot(soz)


```





## working with data frame with dplyr

### Long and wide data structure 

실험을 디자인하고 데이터를 생성하는 사람과는 달리 데이터 분석 전문가의 입장에서 처음 데이터를 받은 후 분석에 필요한 변수와 값을 구분하는 일은 적절한 데이터 분석을 위해 필수적인 과정입니다. 특히 복잡하고 사이즈가 큰 데이터일 경우는 더욱 중요할 수 있으나 대부분 경험에 의존해서 구분이 진행되고 있습니다.  데이터를 Long 또는 Wide 형으로 이해하고 자유롭게 전환하는 능력은 복잡한 데이터의 성공적인 분석과 체계적인 분석 방법을 수립하는데  기여할 수 있습니다.

Wide형 데이터의 경우 샘플 데이터가 늘어날수록 row에 쌓이고 새로운 변수는 column에 쌓이는 방식으로 데이터가 확장되는 형태 입니다. 엑셀에서 볼 수 있는 일반적인 형식으로 다음 그림과 같습니다.

![](images/07/05.png)

long 형 데이터의 경우 ID, variable, value 세가지 변수만 기억하면 되겠습니다. 위 wide형 데이터 경우를 보면 ID, variable, 그리고 value 이 세가지 요인이 주요 구성 요소임을 알 수 있습니다. 샘플을 참조할 수 있는 어떤 변수 (variable)도 ID가 될 수 있으며 2개 이상의 변수가 ID로 지정될 수 있습니다. 참고로 ID를 지정할 경우 해당 ID는 가능하면 중복되지 않는 값들을 갖는 변수를 사용해야 식별자로서 기능을 적절히 수행할 수 있습니다. Long형을 사용할 경우 데이터의 변수가 늘어나도 행의 수만 늘어나므로 코딩의 일관성과 변수들의 그룹을 만들어서  분석하는 등의 장점이 있습니다.

일반적으로 얻어지는 데이터의 형태는 wide형이며 이를 long형으로 변환하기 위해서는 앞에서 잠깐 소개했던 `reshape2` 패키지의 `melt`함수를 사용합니다. 그 반대의 경우 `dcast` 함수를 사용하면 됩니다. `tidyverse` 패키지에 속한 `tidyr` 패키지의 `gather`와  `spread`를 사용할 수도 있습니다. 본 강의에서는 `reshape2` 패키지를 사용합니다. `melt` 함수의  data.frame 에 대한 도움말을 보면 `id.vars` 와 `measure.vars` 파라메터들을 볼 수 있으며 이들이 앞서 설명한 id가 될 변수와 value가 될 변수를 지정해 주는 옵션 입니다. `value.name`을 이용해서 value 값들을 저장하는 변수 이름을 바꿔줄 수 있으며 따로 설정하지 않는 경우 "value"라는 이름으로 저장 됩니다. 아래는 새로운 변수 F가 추가될 때 long 형 데이터에 데이터가 추가되는 경우를 나타낸 그림 입니다. 

![](images/07/06.png)

`airquality` 데이터는 전형적인 wide형 데이터로 특정 날짜에 네 개의 변수에 해당하는 값들을 측정했습니다. 이 데이터를 long형으로 바꿀 경우 ID를 날짜로 하면 데이터들을 식별 할 수 있습니다. 그런데 날짜는 변수가 Month와 Day두 개로 나누어져 있으므로 다음과 같이 두 변수를 식별 변수로 (id로) 사용 합니다.  확인을 위해 상위 5개의 데이터만 가지고 형 변환을 진행해 보겠습니다.


```{r, eval=F}
library(reshape2)
myair <- airquality[1:5,]
myair
myair_mlt <- melt(myair, id.vars=c("Month", "Day"))
myair_mlt
```

`ggplot`을 이용한 그래프 작성에는 위와 같은 long형 데이터가 주로 사용됩니다. R을 이용한 데이터 가시화는 이번 장에서 배우는 `dplyr` 패키지로 wide형 데이터를 편집하고 `melt` 함수로 long형 데이터로 변환 후 `ggplot`을 이용하는 방식으로 수행합니다. 두 데이터 포멧에 대한 좀 더 구체적인 내용은 다음 링크를 참고하시기 바랍니다.
https://www.theanalysisfactor.com/wide-and-long-data/

### dplyr - pipe operator

`dplyr` (https://dplyr.tidyverse.org/) 은 `ggplot`을 개발한 해들리위컴이 (Hadley Wickham) 중심이 되어 만들어 졌으며 `ggplot2`와 함께 `tidyverse`의 (https://www.tidyverse.org/) 핵심 패키지 입니다. 데이터 변환은 앞 7장에서와 같이 R의 builtin 함수에서 이미 제공하는 기능입니다. `dplyr`은 이러한 기능들에 데이터 크기나 분석의 속도, 편의성을 향상시켜 새롭게 만들어놓은 패키지 입니다. 앞에서 배운 `apply`와 같은 행렬 연산 기능과 `subset`, `split`, `group` 와 같은 행렬 편집 기능을 더하여 만들어진 도구라고 할 수 있습니다.

`dplyr`의 사용을 위해서는 `ggplot`의 `+` 오퍼레이터와 유사하게 여러 명령을 연속적으로 수행하도록 해주는 `%>%` 파이프 오퍼레이터의 이해가 필요합니다. 파이프 오퍼레이터의 작동법은 간단히 `%>%`의 왼쪽 코드의 결과를 출력으로 받아 오른쪽 코드의 입력 (첫번째 파라미터의 값)으로 받아들이는 작동을 합니다. 다음 예에서 보면 `sin(pi)` 와 같은 함수의 일반적인 사용법 대신 `pi %>% sin` 처럼 사용해도 똑같은 결과를 보여줍니다. `cos(sin(pi))`와 같이 여러 합수를 중첩하여 사용할 경우와 비교해서 코드의 가독성이나 효율 측면에서 크게 향상된 방법을 제공해 줍니다.


```{r, eval=F}
library(dplyr)

pi %>% sin
sin(pi)
pi %>% sin %>% cos
cos(sin(pi))
```


특히 ` %>% `는 이후 설명할 `dplyr`의 `group_by`, `split`, `filter`, `summary` 등의 행렬 편집/연산 함수를 빈번히 다양한 조합으로 쓰게되는 상황에서 더 큰 효과를 발휘할 수 있습니다. 그에 앞서 pipe 오퍼레이터의 예제를 좀 더 살펴보겠습니다.


![](images/07/02.png)

pipe operator의 왼쪽 구문의 결과가 오른쪽 구문의 첫 번째 파라미터의 입력 값으로 처리된다고 말씀 드렸습니다. 즉, 함수에서 사용되는 파라미터가 여러개일 경우가 있으므로 기본적으로 ` %>% ` 의 왼쪽 구문의 출력 값은 오른쪽 구문 (함수)의 첫 번째 인자의 입력값으로 들어가는 것 입니다. 이는 다음 예들을 통해서 명확히 알 수 있습니다. 먼저  `paste`함수는 그 파라미터로 `,`로 구분되는 여러개의 입력 값을 가질 수 있습니다. 따라서 다음 코드는 `x`가 `paste`의 첫 번째 파라미터로 들어가게 되어 `"1a", "2a", "3a", "4a", "5a"`로 a 앞에 x 값들이 붙어서 출력된 것을 알 수 있습니다.


```{r, eval=F}
x <- 1:5
x %>% paste("a", sep="")
```

특정 데이터셋의 컬럼별 평균을 구하고 각 평균의 합을 구할 경우를 생각해 봅시다. R에서는 `colMeans`라는 특별한 함수를 제공하여 컬럼별로 평균을 계산해 줍니다. 그 후 sum 함수를 사용하여 최종 원하는 값을 얻을 수 있습니다. 이러한 코드를 `%>%` 오퍼레이터를 사용한 경우의 코드와 비교해 볼 수 있습니다.

```{r, eval=F}
x <- data.frame(x=c(1:100), y=c(201:300))
sum(colMeans(x))

x <- data.frame(x=c(1:100), y=c(201:300))
x %>% colMeans %>% sum
```


그럼 만약 두 번째 파라미터에 입력으로 왼쪽 구문의 출력을 받아들이고 싶을 경우는 어떻게 할까요? 그럴때는 place holer라는 `.` 을 사용하면 되겠습니다. `round` 함수는 두 개의 파라미터를 설정할 있 이으며 digits 라는 두 번째 파라미터에 값을 pipe operator로 넘겨주고 싶을 경우 아래와 같이 표현할 수 있습니다.

```{r, eval=F}
6 %>% round(pi, digits=.)
round(pi, digits=6)
```


### dplyr - Important functions

이제 본격적으로 `dplyr` 함수를 사용해 보겠습니다. `dplyr`을 구성하는 중요한 함수는 다음 6가지가 있습니다.

* `select()` -	select columns
* `filter()` -	filter rows
* `arrange()` -	re-order or arrange rows
* `mutate()` -	create new columns
* `summarise()` -	summarise values
* `group_by()` -	allows for group operations in the “split-apply-combine” concept
* `join()` - Merge two data.frames (`left_join()`, 'right_join()`, 'inner_join()`, 'full_join()`)

이 함수들은 ` %>% `와 함께 쓰이면서 강력한 성능을 발휘합니다. `summarise` 함수는 특정 값들의 통계 값을 계산해 주는 함수이며 그 외 5개 함수들은 행렬 편집을 위한 함수들로 보시면 되겠습니다. 각각의 설명보다는 직접 간단한 예제를 수행하면서 각각의 기능을 살펴보고 왜 `dplyr`이 널리 사용되고 그 장점이 무엇인지 파악해 보도록 하겠습니다.

예제에 사용할 데이터는 `iris` 데이터로 R을 설치하면 기본으로 들어있는 데이터 입니다. 세 종류의 iris 품종에 대한 꽃잎과 꽃받침의 length와 with를 측정해 놓은 데이터 입니다. `head`와 `str` 명령어를 `%>%`를  이용해서 데이터를 살펴 봅니다. 

```{r, eval=F}
iris %>% head(10)
iris %>% str
```

#### filter 

먼저 아래와 같이 `filter` 함수를 사용해서 원하는 조건의 데이터 (샘플)을 골라낼 수 있습니다. 

```{r, eval=F}
head(iris)
filter(iris, Species=="setosa", Species=="versicolor")
filter(iris, Species=="setosa" & Species=="versicolor")
filter(iris, Species=="setosa" | Species=="versicolor") %>% dim

```


`filter`의 `,`로 구분되는 매개변수는 `and` 로직으로 묶인 조건입니다. 지난 강좌에서 보셨듯 R에서 `and`는 `&`,  `or`는 `|`, 그리고 not은 `!` 으로 사용하면 되며 `filter`에서 `,`로 구분된 조건은 `and`와 같다고 보시면 되겠습니다. 


![](images/07/03.png)

Image from (https://r4ds.had.co.nz/)


### arrange 

`arrange()`는 샘플들의 배열 순서 즉, row의 순서를 바꾸는 기능을 수행합니다. 기본으로 크기가 커지는 순서로 정렬이 진행되며 작아지는 순서를 원할 경우 `desc` 함수를 사용할 수 있습니다. 


```{r, eval=F}
arrange(iris, Sepal.Length)
arrange(iris, desc(Sepal.Length))
arrange(iris, Sepal.Length, Sepal.Width)
```

### select

`select()` 는 주어진 데이터셋으로부터 관심있는 변수를 (column) 선택하여 보여줍니다. 다음 helper 함수들은 select 함수와 같이 유용하게 쓰일 수 있습니다. 

* starts_with("abc") -	"abc" 로 시작하는 문자열을 갖는 변수 이름 
* ends_with("xyz") -	"xyz"으로 끝나는 문자열을 갖는 변수 이름 
* contains("ijk") -	"ijk" 문자열을 포함하는 변수 이름 
* matches("(.)\\1") - 정규식, 반복되는 문자 


```{r, eval=F}
head(iris)
select(iris, Species, everything())
select(iris, -Species)
select(iris, starts_with('S'))
select(iris, obs = starts_with('S'))
```

아래는 `matches` 함수를 사용한 방법 입니다. 좀 더 복잡한 패턴을 적용하여 변수들을 선택할 수 있으며 `grep` 함수를 사용할 경우도 정규식 패턴을 적용할 수 있습니다. 아래 `(.)\\1`은 하나의 문자 `.`가  (어떤 문자든) 한 번 더 `\\1` 사용된 변수 이름을 말하며 이는 `aavar` 의 `aa`밖에 없으므로 `aavar`가 선택됩니다. `grep`에서 `^` 표시는 맨 처음을 나타내므로 `^S`는 S로 시작하는 문자가 되겠습니다. 따라서 `grep("^S", colnames(iris))`의 경우 컬럼 이름 중 S로 시작하는 이름은 True로 그렇지 않으면 False 값을 리턴합니다. 


```{r, eval=F}
iris2 <- rename(iris, aavar = Petal.Length)
select(iris2, matches("(.)\\1"))
tmp <-iris[,3:5]
colnames(iris)[grep("^S", colnames(iris))]
iris[,grep("^S", colnames(iris))]
tmp
```

### mutate

`mutate()` 함수는 새로운 변수를 추가할 수 있는 기능을 제공하며 앞에서 배웠던 `within()`과 비슷하다고 볼 수 있습니다. 아래와 같이 `mutate`함수는 sepal_ratio라는 변수를 새로 만들어서 기존 iris 데이터들과 함께 반환해 줍니다. 


```{r, eval=F}
iris2 <- mutate(iris, sepal_ratio = Sepal.Length/Sepal.Width)
head(iris2)
```


### summarise

`summarise()`는 `data.frame`내 특정 변수의 값들로 하나의 요약값/대푯값을 만들어 줍니다. `summarise` 함수는 단독으로 쓰이기 보다는 `group_by()` 기능과 병행해서 쓰이는 경우에 유용하게 쓰입니다. `summarise_all()` 함수를 사용하면 모든 변수에 대해서 지정된 함수를 실행합니다. 


```{r, eval=F}
summarise(iris, mean(Sepal.Length), m=mean(Sepal.Width))
by_species <- group_by(iris, Species)
summarise(by_species, mean(Sepal.Width))
summarise_all(by_species, mean)
summarise_all(by_species, sd)
```

### join 

`join` 함수는 앞 7장에서 배운 `merge` 함수와 유사한 기능을 수행하는 `dplyr` 패키지에 속한 함수 입니다. 네 가지 종류의 함수가 있으며 (`left_join()`, 'right_join()`, 'inner_join()`, 'full_join()`) 기본적으로 공통되는 이름의 변수를 (key) 이용해서 공통되는 샘플끼리 자동으로 병합해 주는 기능을 수행합니다. 7장에서 사용한 예에 동일하게 적용해 보고 7장의 결과와 비교해 보시기 바랍니다.

```{r, eval=F}
df1 <- data.frame(id=c(1,2,3,4,5,6), age=c(30, 41, 33, 56, 20, 17))
df2 <- data.frame(id=c(4,5,6,7,8,9), gender=c("f", "f", "m", "m", "f", "m"))

inner_join(df1, df2)
left_join(df1, df2)
right_join(df1, df2)
full_join(df1, df2)
```

위 예에서는 `id`라는 공통되는 변수에 의해서 병합이 수행되는 것을 알 수 있습니다. 



### code comparison

이제 split, apply, combine을 활용하여 평균을 구하는 코드와 `dplyr` 패키지를 사용하여 만든 코드를 비교해 보도록 하겠습니다. `split`은 `factor`형 변수인 Species를 기준으로 `iris` 데이터를 나누어 주는 역할을 하며 `lapply`는 `list` 형 데이터인 `iris_split`을 각 리스트의 각각의 원소들에 대해서 임의의 함수 `function(x)...` 를 수행하는 역할을 합니다. 마지막 `data.frame`으로 최종 경로를 combine 합니다.

```{r, eval=F}
iris_split <- split(iris, iris$Species)
iris_means <- lapply(iris_split, function(x){colMeans(x[,1:4])})
iris_means_df <- data.frame(iris_means)
iris_means_df
```

위 코드를 한 줄로 사용하여 최종 iris_means_df 데이터를 를 구한다면 다음과 같이 됩니다. 한눈에 코드가 들어오지 않고 이렇게 중첩해서 함수를 사용하는 습관은 어떤 프로그래밍 언어에서도 권장하지 않습니다.

```{r, eval=F}
iris_means_df <- data.frame(lapply(split(iris, iris$Species), function(x){colMeans(x[,1:4])}))
```


아래는 `dplyr` 패키지를 사용한 코드 입니다.

```{r, eval=F}
iris_means_df2 <- iris %>% 
  group_by(Species) %>% 
  summarise_all(mean)
```


위에서 보듯 `dplyr` 패키지를 사용할 경우 그 결과는 같으나 코드의 가독성과 효율성면에서 장점을 보여줍니다. `iris` 데이터를 받아서 Species에 명시된 그룹으로 나누고 `mean` 함수를 모든 컬럼에 대해서 사용하라는 의미 입니다. 

이제 `ggplot`을 이용하여 각 평균에 대한 `barplot`을 그려보도록 하겠습니다. 지난 예제와는 달리 `ggplot`에서는 data만 명시해 주고 `geom_bar`에 `aes`와 `stat`을 모두 사용한 것이 다릅니다. ggplot 구문에서 지정해주는 `aes` 등의 옵션은 하위 geom_xxx 레이어들에 모두 적용이 되고 각 geom_xxx 레이어에서 지정해주는 `aes`는 해당 레이어에서만 효과를 나타냅니다.


```{r, eval=F}
ggplot(iris_means_df2) +
  geom_bar(aes(x=Species, y=Sepal.Length), stat="identity")
```


`dplyr`의 전신이라 할 수 있는 `plyr` 패키지는 다음과 같이 설명이 되어 있습니다. *A set of tools for a common set of problems: you need to split up a big data structure into homogeneous pieces, apply a function to each piece and then combine all the results back together.* 즉 split-apply-combine 세 가지 동작을 쉽게 할 수 있도록 만들어 놓은 툴 입니다. R이 다른 언어에 비해 데이터 분석에서 주목을 받는 이유로 `split`, `apply` 등의 행렬 연산 함수가 발달한 것을 내세우는데 `dplyr`은 이들을 보다 더 편리하게 사용할 수 있도록 만들어 놓은 것 입니다.


위 `dplyr` 패키지의 기능을 `ggplot2` 패키지의 기능들과 함께 사용할 수도 있습니다. 보통은 앞서와 같이 결과를 특정 변수에 저장한 후 도표 등을 그리지만 다음과 같이 `%>%` 를 사용하여 `plot` 까지 함께 볼 수도 있습니다.

```{r, eval=F}
iris %>%
  group_by(Species) %>%
  summarise_all(mean) %>%
  ggplot() +
  geom_bar(aes(x=Species, y=Sepal.Length), stat="identity")
```



## dplyr example iris 

`dplyr`패키지를 이용해서 `iris` 품종별로 꽃과 꽃받침의 넓이와 길이의 평균을 비교하는 bar그래프를 (error bar 포) 그려보겠습니다. 이를 위해서는 먼저 iris 데이터를 품종별로 grouping 할 필요가 있습니다. 


```{r, eval=F}
iris2 <- iris %>% group_by(Species)
str(iris2)
```

이제 그룹별로 꽃과 꽃받침 길이와 넓이의 평균을 일괄적으로 구합니다.  

```{r, eval=F}
iris3 <- iris2 %>% 
  summarize_all(mean)
iris3
```


<!-- error bar를 위한 표준편차까지 일괄적으로 구하기 위해서는 다음과 같이 수행합니다. 사용되는 함수 (mean, sd)를 여러개 전달할 필요가 있으므로 `list` 형태로 진행합니다. -->

<!-- ```{r, eval=F} -->
<!-- iris3 <- iris2 %>%  -->
<!--   summarize_all(list(mean=mean, sd=sd)) -->
<!-- str(iris3) -->
<!-- ``` -->


이제 이 값들을 이용해서 barplot으로 그려봅니다. 그래프의 x축은 species별 Length나 Width mean 값으로 하고 y축은 각 해당하는 값들로 `stat="identity"'로 넣어주면 될 듯 합니다.  ggplot을 이용해서 그래프를 그리기 위한 long형 데이터로 전환해보면 다음과 같습니다. 
```{r, eval=F}
iris4 <- iris3 %>% 
  melt(id.var="Species")
str(iris4)
```

위 데이터로 barplot을 그릴 수 있습니다. 

```{r, eval=F}
ggplot(iris4, aes(x=variable, y=value, fill=Species)) +
  geom_bar(stat="identity", position="dodge")
```


위 일련의 과정을 다음과 같이 %>% 로 연속적으로 구현할 수 있습니다. 


```{r, eval=F}
iris_mean <- iris %>% 
  group_by(Species) %>% 
  summarize_all(mean) %>% 
  melt(id.var="Species")

ggplot(iris2, aes(x=variable, y=value, fill=Species)) +
  geom_bar(stat="identity", position="dodge")
```

error bar 구현을 위해서는 각 그룹별 표준편차 `sd` 값이 필요합니다. 동일한 방법으로 sd 데이터를 구합니다. 

```{r, eval=F}
iris_sd <- iris %>% 
  group_by(Species) %>% 
  summarize_all(sd) %>% 
  melt(id.var="Species")

```

이제 두 데이터를 병합 하겠습니다. 두 데이터를 병합할 때 key가 되는 변수가 필요하며 기본으로 동일한 이름을 가진 변수를 사용하지만 이 예제에서는 모든 변수가 동일한 이름을 가지고 있습니다. 따라서 by라는 옵션으로 key 변수를 지정해줄 수 있으며 다음과 같이 두 개 이상의 변수도 지정할 수 있습니다. 

```{r, eval=F}

iris_new <- inner_join(iris_mean, iris_sd, by=c("Species", "variable"))
head(iris_mean)
head(iris_sd)
head(iris_new)
```

위와 같이 각 해당하는 샘플의 mean과 sd 값을 직접 비교해 보면 적절한 value 값들이 병합된 것을 알 수 있습니다. 단, `value`라는 변수 이름이 두 테이블에서 동일하게 사용되어 병합될 경우 value.x, value.y와 같이 자동으로 변수 이름이 다르게 할당 됩니다. 이제 위 데이터를 이용해서 barplot을 그려 보겠습니다. 

```{r, eval=F}

ggplot(iris_new, aes(x=variable, y=value.x, fill=Species))+
  geom_bar(stat="identity", position="dodge")

```


여기에 error bar를 추가하기 위해서는 다음과 같이 `geom_errorbar`라는 함수를 사용할 수 있습니다.  아래에서 `position_dodge(0.9)`는 error bar의 위치를 맞추기 위한 옵션으로 width를 사용할 경우는 일반적으로 `position_dodge(0.9)`를 사용한다고 외우는 것도 괜찮습니다. 


```{r, eval=F}

ggplot(iris_new, aes(x=variable, y=value.x, fill=Species))+
  geom_bar(stat="identity", position="dodge") +
  geom_errorbar(aes(ymin=value.x-value.y, ymax=value.x+value.y), 
                position=position_dodge(0.9), 
                width=0.4)

```



<!-- ```{r, eval=F} -->
<!-- ggplot(subdat.mlt, aes(x=device_name, y=value, fill=device_name)) + -->
<!--   geom_violin(trim=FALSE) + -->
<!--   geom_jitter(shape=16, position=position_jitter(0.1), color="#00000055") + -->
<!--   scale_fill_brewer(palette="Blues") + -->
<!--   geom_boxplot(width=0.1, fill="white")+ -->
<!--   theme_minimal() + -->
<!--   labs(y="OD600",  -->
<!--        x="DmpR mutant sensors", -->
<!--        fill=element_blank()) + -->
<!--   theme(legend.position = "none",  -->
<!--         axis.text = element_text(size=12), -->
<!--         axis.title=element_text(size=14)) -->

<!-- ``` -->


---


<a rel="license" href="http://creativecommons.org/licenses/by-nc-nd/4.0/"><img alt="크리에이티브 커먼즈 라이선스" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-nd/4.0/88x31.png" /></a><br />이 저작물은 <a rel="license" href="http://creativecommons.org/licenses/by-nc-nd/4.0/">크리에이티브 커먼즈 저작자표시-비영리-변경금지 4.0 국제 라이선스</a>에 따라 이용할 수 있습니다.






